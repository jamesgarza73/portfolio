{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38101079",
   "metadata": {},
   "source": [
    "# AIP 4 - Project Rechin\n",
    "## Strategic Thinking - CA4 - Sprint 2\n",
    "## Project Rechin - Can an AI Beat a Human Trader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56251536",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef908e3",
   "metadata": {},
   "source": [
    "## Model configuration: customisation posibilities"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3def6d37",
   "metadata": {},
   "source": [
    "additional_metrics = ['accuracy']\n",
    "batch_size = 128\n",
    "embedding_output_dims = 15\n",
    "loss_function = BinaryCrossentropy()\n",
    "max_sequence_length = 300\n",
    "num_distinct_words = 5000\n",
    "number_of_epochs = 5\n",
    "optimizer = Adam()\n",
    "validation_split = 0.20\n",
    "verbosity_mode = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1085d3f6",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9610b",
   "metadata": {},
   "source": [
    "## LSTM Layer parameters and defaults"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fba1da0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-31T11:58:07.329231Z",
     "start_time": "2021-10-31T11:58:07.102367Z"
    }
   },
   "source": [
    "tf.keras.layers.LSTM(\n",
    "    units,\n",
    "    activation='tanh', \n",
    "    recurrent_activation='sigmoid',\n",
    "    use_bias=True, \n",
    "    kernel_initializer='glorot_uniform',\n",
    "    recurrent_initializer='orthogonal',\n",
    "    bias_initializer='zeros', \n",
    "    unit_forget_bias=True,\n",
    "    kernel_regularizer=None, \n",
    "    recurrent_regularizer=None, \n",
    "    bias_regularizer=None,\n",
    "    activity_regularizer=None, \n",
    "    kernel_constraint=None, \n",
    "    recurrent_constraint=None,\n",
    "    bias_constraint=None, \n",
    "    dropout=0.0, \n",
    "    recurrent_dropout=0.0,\n",
    "    return_sequences=False, \n",
    "    return_state=False, \n",
    "    go_backwards=False, \n",
    "    stateful=False,\n",
    "    time_major=False, \n",
    "    unroll=False, **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebfddd",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf21065",
   "metadata": {},
   "source": [
    "## Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfb67dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T18:25:01.521869Z",
     "start_time": "2021-11-10T18:24:55.180608Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data acquisition\n",
    "import pickle\n",
    "import mysql.connector \n",
    "from sqlalchemy import create_engine\n",
    "import os\n",
    "\n",
    "# Data analysis basics\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "#EDA\n",
    "#import pandas_profiling # https://anaconda.org/conda-forge/pandas-profiling # conda install ipywidgets\n",
    "\n",
    "#Machine Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# ML > LSTM \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# ML > Save model\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n",
    "# ML > Optimizer > Adam just for trying\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# ML > Metrics\n",
    "from tensorflow.keras import metrics as metrics_tf\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# ML > GPU for tensorflow\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Viz\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "import seaborn as sns\n",
    "# Set plot size \n",
    "from pylab import rcParams\n",
    "%matplotlib inline\n",
    "\n",
    "#Cosmetic: Disabling notebook warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Plot LSTM Model\n",
    "# https://keras.io/api/utils/model_plotting_utils/\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8816cd35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T18:25:01.568742Z",
     "start_time": "2021-11-10T18:25:01.557771Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0335e1bc",
   "metadata": {},
   "source": [
    "## Check If GPU or CPU\n",
    "\n",
    "GPU runs much faster for model training than CPU but you must install CUDA first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6c7d19c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T18:25:01.614619Z",
     "start_time": "2021-11-10T18:25:01.601657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "gpu_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpu_devices:\n",
    "    print('Using GPU')\n",
    "    tf.config.experimental.set_memory_growth(gpu_devices[0], True)\n",
    "else:\n",
    "    print('Using CPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f63aea",
   "metadata": {},
   "source": [
    "## Credentials To Login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f3871a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = \"enterLater\"\n",
    "startDate = '2021-10-07'\n",
    "missingSymbols = []\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"database-rechin.123456.eu-west-1.rds.amazonaws.com\" #Antonio's AWS\n",
    "uname=\"admin\"\n",
    "pwd=\"rechin\"\n",
    "dbName = 'rechindbcct'\n",
    "\n",
    "# Connect to Specific Database\n",
    "db = mysql.connector.connect(host= hostname,\n",
    "  user=uname, password=pwd, database = dbName)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb144f1",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c792f20",
   "metadata": {},
   "source": [
    "# Data acquisition and cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5860371",
   "metadata": {},
   "source": [
    "## Get Master Dataframe\n",
    "For now we are using a pickled dataframe until we can get our model sorted out then we will get the data from the  AWS database that we have inputed and can retreive the data needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ba03f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:19.154481Z",
     "start_time": "2021-11-07T11:22:19.140501Z"
    }
   },
   "outputs": [],
   "source": [
    "class Stock():\n",
    "    def __init__(self, symbol):\n",
    "        self.symbol = symbol\n",
    "        self.data = []\n",
    "        self.indicators = []\n",
    "        \n",
    "    def getStockData(self, source, user):\n",
    "        '''This function gets the stock data either from the local computer or online. Returns a dataframe of the \n",
    "        one minute stock data.\n",
    "\n",
    "        Args:\n",
    "        symbol (string): this is the symbol of the data that is needed.\n",
    "        source (string): This string is for either online or local hard drive access of stock one minute data.\n",
    "        user (string): This is the number in the future you want to predict out.\n",
    "\n",
    "        Returns:\n",
    "        df (dataframe): stock data by the symbol requested in dataframe sorted by date.  Indicators will be added later.\n",
    "\n",
    "        Notes: \n",
    "        '''\n",
    "        if source == 'local':\n",
    "            if user == 'antonio':\n",
    "                df = pickle.load(open( \"D:\\Rechin_CCT\\Rechin\\data\\masterDf_Phase4.p\", \"rb\" ))\n",
    "                df = df[df.Symbol == symbol]\n",
    "                # Make sure the data is sorted ascending order by datetime.\n",
    "                df.sort_values(by=['date'], inplace=True)\n",
    "                df.reset_index(inplace=True, drop=True)\n",
    "                df.head()\n",
    "            elif user == 'james':\n",
    "                df = pickle.load(open( \"D:\\Downloads\\masterDf_Phase4.p\", \"rb\" ))\n",
    "                df = df[df.Symbol == symbol]\n",
    "                # Make sure the data is sorted ascending order by datetime.\n",
    "                df.sort_values(by=['Date'], inplace=True)\n",
    "                df.reset_index(inplace=True, drop=True)\n",
    "                df.head()\n",
    "            else:\n",
    "                print('User not recognized!')\n",
    "                df = pd.DataFrame()\n",
    "        elif source == 'cloud':\n",
    "            # Credentials to database connection\n",
    "            hostname=\"database-rechin.123456.eu-west-1.rds.amazonaws.com\" #Antonio's AWS\n",
    "            uname=\"admin\"\n",
    "            pwd=\"rechin123\"\n",
    "            dbName = 'rechindbcct'\n",
    "            \n",
    "            # Connect to Specific Database\n",
    "            db = mysql.connector.connect(host= hostname,\n",
    "              user=uname, password=pwd, database = dbName)\n",
    "            \n",
    "            # Get all symbols from database\n",
    "            cursor = db.cursor()\n",
    "            cursor.execute(\"\"\"SELECT * FROM indicators WHERE symbol = (%s)\"\"\", (self.symbol,))\n",
    "            result = cursor.fetchall()\n",
    "            \n",
    "            # Create dataframe for symbol\n",
    "            columns = [i[0] for i in cursor.description]\n",
    "            df = pd.DataFrame(result, columns=columns)\n",
    "        #df = df.drop(columns=['data_vendor','created_date', 'last_updated'])\n",
    "        df.sort_values(by=\"Date\", inplace=True)\n",
    "        df.reset_index(inplace=True, drop=True)\n",
    "        self.data = df\n",
    "        return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eaae514",
   "metadata": {},
   "source": [
    "## Now time to clean our dataset\n",
    "There are a few things needed to be done here.  We need to drop columns and deal with some 0 values in volume.  From there the dataset is ready to add technical indicators. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbe06f4",
   "metadata": {},
   "source": [
    "## Now Put our Label into the Last Column of DataFrame\n",
    "The preceding columns are features and the right column will will be the label column.  This is the column we will tell the machine we want it to predict."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d4afd",
   "metadata": {},
   "source": [
    "# Data transformations for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27972f46",
   "metadata": {},
   "source": [
    "## Split the DataSet into Train and Test\n",
    "Based on the split amount we selected above we will split the dataset into two, Train and Test.  Decided to split the dataset this way rather than using the sklearn split function as it shuffles the dataset and we cannot do that in a time series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853b920",
   "metadata": {},
   "source": [
    "## Scale the Dataset for the Machine to Predict\n",
    "Scaling makes it easier for the machine to predict as it deals with outliers and puts all within a -1 to 1 range."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3561c",
   "metadata": {},
   "source": [
    "## Methods to Reshape the dataset and Later Model Evaluation and Predictions\n",
    "These methods will be used to put into an array the lookback periods into each row removing the first lookback rows.  Also it deletes the prediction rows at the end of the prediction data. It will also turn the data into arrays for us in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "812f1bd6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:19.249771Z",
     "start_time": "2021-11-07T11:22:19.155454Z"
    }
   },
   "outputs": [],
   "source": [
    "class dataTransformer():\n",
    "    def __init__(self, scaler, data):\n",
    "        self.scaler = scaler\n",
    "        self.data = data\n",
    "    ## Now time to clean our dataset\n",
    "    #There are a few things needed to be done here.  \n",
    "    #We need to drop columns and deal with some 0 values in volume.  \n",
    "    #From there the dataset is ready to add technical indicators.\n",
    "    def CleanImpute(self, data, impute):\n",
    "        '''This function replaces missing volume values in the dataset with the rolling volume average.  \n",
    "        If imputed is true the missing volume values is replaced volume average.  Columns are dropped \n",
    "        that are not needed and index is reset.\n",
    "        If impute is false the column not needed is dropped and the index is reset.\n",
    "\n",
    "        Args:\n",
    "        data (dataFrame): This is the data that will be cleaned with imputed data.\n",
    "\n",
    "        Returns:\n",
    "        df (dataframe): Cleaned dataframe with either imputed data and removed columns or just removed colomns\n",
    "        depending if imputed is true or false.\n",
    "\n",
    "        Notes: \n",
    "        '''\n",
    "        df = data.copy()\n",
    "        if impute:\n",
    "            # Clean dirty data\n",
    "            ### Imputing 20K zeroes with rolling average for the last 360 minutes\n",
    "            data[\"volume_mean\"]=data[\"volume\"].replace(0, np.nan)\n",
    "            data[\"volume_mean\"] = data[\"volume_mean\"].fillna(data[\"volume_mean\"].rolling(360,min_periods=1).mean())\n",
    "\n",
    "            # Now that dataset has imputed values we make our final dataframe to use for our model.\n",
    "            df = data.copy()\n",
    "            \n",
    "            # replace column with missing values with imputed column.\n",
    "            df['volume'] = df['volume_mean']\n",
    "\n",
    "            # Now drop columns that will not be needed for our model.\n",
    "            df = df.drop(columns=['volume_mean'])\n",
    "            df = df.drop(columns=['Symbol'])\n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "        else:\n",
    "            df = df.drop(columns=['Symbol'])\n",
    "            df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def Index_ReorderIndependent(self, df):\n",
    "        '''This function puts the label into the last column of the dataframe.  \n",
    "        The preceding columns are features and the right column will will be the label column.  \n",
    "        This is the column we will tell the machine we want it to predict.\n",
    "\n",
    "        Args:\n",
    "        data (dataFrame): This is the data that will be reorderd into label last column.\n",
    "\n",
    "        Returns:\n",
    "        df (dataframe): Reordered dataframe with features on rows 0 to second to last and last row is the\n",
    "        label or target value.\n",
    "\n",
    "        Notes: \n",
    "        We need to add to this function which is the label and do this programatically.  \n",
    "        '''\n",
    "        df.set_index(pd.DatetimeIndex(df[\"Date\"]), inplace=True)\n",
    "        df.drop(columns=['Date'],inplace=True)\n",
    "        first_column = df.pop('Close')\n",
    "        # insert column using insert(position,column_name, first_column) function\n",
    "        df.insert(len(df.columns), 'Close', first_column)\n",
    "        return df\n",
    "    \n",
    "    def GetTrainTest(self, df, train_split_percentage):\n",
    "        '''This function takes our dataset and splits it into train dataset and test dataset.  This will \n",
    "        help our machine learn and then test the model to validate the model.\n",
    "\n",
    "        Args:\n",
    "        data (dataFrame): This is the data that you will split into train and test.\n",
    "        train_split_percentage (float): This is percentage you want to split the dataset by.\n",
    "\n",
    "        Returns:\n",
    "        train (array): dataset to use for the training of the model.\n",
    "        test (array): dataset to validate the model training.\n",
    "\n",
    "        Notes: \n",
    "        '''\n",
    "        # Get the index where we will split the dataset\n",
    "        splitIndex = int(round(len(df) * train_split_percentage,0))\n",
    "\n",
    "        # Split the dataset into two\n",
    "        train = df.iloc[:splitIndex,:]\n",
    "        test = df.iloc[splitIndex+1:,:]\n",
    "        return train, test\n",
    "    \n",
    "    def scaleData(self, train, test):\n",
    "        '''This function scales the dataset to make easier for the LSTM model to train and predict.  This deals\n",
    "        with outliers.\n",
    "\n",
    "        Args:\n",
    "        train (array): dataset to scale for the training of the model.\n",
    "        test (array): dataset to scale for the testing the model.\n",
    "\n",
    "        Returns:\n",
    "        train (array): scaled dataset to use for the training of the model.\n",
    "        test (array): scaled dataset to validate the model training.\n",
    "        scaler (scaler model): this model will be used later to inverse transform the predicted label.\n",
    "\n",
    "        Notes: \n",
    "        will add MinMaxScaler to try another scaler and see if this improves accuracy and avoids overfitting.\n",
    "        '''\n",
    "        if self.scaler == 'StandardScaler':\n",
    "            # Call the scaler function\n",
    "            scaler = StandardScaler()\n",
    "            # Scale the Train & Test Data with same fitting (scaling factor)\n",
    "            scaler = scaler.fit(train)\n",
    "            scaled_train = scaler.transform(train)\n",
    "            scaled_test = scaler.transform(test)\n",
    "        elif self.scaler == 'MinMaxScaler':\n",
    "            # Need to put in minmaxscaler\n",
    "            pass\n",
    "        return scaled_train, scaled_test, scaler\n",
    "    \n",
    "    # Google style documentation on functions:\n",
    "    #https://google.github.io/styleguide/pyguide.html\n",
    "    def reformatDataset(self, n_past, n_future, data):\n",
    "        '''This function takes the dataset input and returns the data in a format usable by the LSTM Model.  \n",
    "        The dataset is reshaped to the number of past minutes for each iteration and then \n",
    "        gets the predicted minutes.  At the end of the function the data is converted into an array.\n",
    "\n",
    "        Args:\n",
    "        n_past (int): This is the number of past observations to go back to use in each row for the LSTM.\n",
    "        n_future (int): This is the number in the future you want to predict out.\n",
    "        data (dataFrame): This is the data that you will reshape into features and label.\n",
    "\n",
    "        Returns:\n",
    "        features (array): features in shape ready for LSTM training or LSTM predictions.\n",
    "        label (array): label ready for LSTM training or LSTM predictions.\n",
    "\n",
    "        Notes: \n",
    "        https://github.com/bnsreenu/python_for_microscopists/blob/master/181_multivariate_timeseries_LSTM_GE.py\n",
    "        '''\n",
    "        # Create empty arrays to input the formated data\n",
    "        xDataset = []\n",
    "        yDataset = []\n",
    "        # Loop through the dataset and append both the feature and label array in preparation for LSTM model.\n",
    "        for i in range(n_past, len(data) - n_future + 1):\n",
    "            xDataset.append(data[i - n_past:i, 0:data.shape[1]])\n",
    "            yDataset.append(data[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "        # Convert the data into numpy arrays.\n",
    "        xDataset, yDataset = np.array(xDataset), np.array(yDataset)\n",
    "        return xDataset, yDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32f9cb4",
   "metadata": {},
   "source": [
    "# Now Create our RNN LSTM Model and Print Summary\n",
    "This is model that we have created over various, books, online articles, papers and youtube videos... countless hours."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68106d5c",
   "metadata": {},
   "source": [
    "## Notes on Early Stopping\n",
    "\n",
    "\n",
    "\n",
    "* **EarlyStopping**: Stop training when a monitored mertric has stopped omproving.\n",
    "\n",
    "* **<font color=red>monitor</font>**: quantity to be monitored\n",
    "\n",
    "* **<font color=red>min_delta</font>**: minimum change in the monitored quantity to qualify as an improvement, i.e. an absolute change of less than min_delta will count as no improvement.\n",
    "\n",
    "* **<font color=red>patience</font>**: numbers of epochs with no improvement after which training will be stopped.\n",
    "\n",
    "* **ReduceLROnPLateau**: Reduce learning rate when a metric has stopped improving.\n",
    "* **<font color=red>factor</font>**: factor by which the learning rate will be reduced. <font color=red>new_lr = lr * factor</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de56a35",
   "metadata": {},
   "source": [
    "### Notes on size of n_units\n",
    "\n",
    "n_neurons = round(self.X_train.shape[1] / (neuron_scale_factor*(self.X_train.shape[2]+1)))\n",
    "\n",
    "\n",
    "$\n",
    "N_{h} = \\frac{N_{s}}{(\\alpha*(N_{i}+N_{o}))}\n",
    "$\n",
    "\n",
    "Ni = number of input neurons.\n",
    "\n",
    "No = number of output neurons.\n",
    "\n",
    "Ns = number of samples in training data set.\n",
    "\n",
    "α = an arbitrary scaling factor usually 2-10.\n",
    "\n",
    "Source: https://ai.stackexchange.com/questions/3156/how-to-select-number-of-hidden-layers-and-number-of-memory-cells-in-an-lstm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cab802ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:19.280714Z",
     "start_time": "2021-11-07T11:22:19.250609Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self, loss, optimizer, epochs, X_train, y_train, X_test, y_test, activation, \n",
    "            layerNumber, modelName, patience, customBatchSize, neuron_scale_factor, split):\n",
    "        self.modelName = modelName\n",
    "        self.layerNumber = layerNumber\n",
    "        self.model = Sequential()\n",
    "        self.loss = loss\n",
    "        self.optimizer = optimizer\n",
    "        self.epochs = epochs\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.activation = activation\n",
    "        self.patience = patience\n",
    "        self.customBatchSize = customBatchSize\n",
    "        self.logs_save_path = \"logs/fit/\"\n",
    "        self.model_save_path = \"logs/model/\"\n",
    "        self.neuron_scale_factor = neuron_scale_factor\n",
    "        self.split = split\n",
    "        \n",
    "    def createModel(self):\n",
    "        '''This function creates our model based on a number of input arguements.  Firstly we want to clear\n",
    "        any prior sessions to get a good clean model.  Number of Nuerons is also processed here based on the\n",
    "        size of the dataset and features.  Then build the number of layers based on the inputs.  Finally,\n",
    "        compile the model and print a summary of the model.\n",
    "\n",
    "        Args:\n",
    "        loss (string): This string is the model which loss function used in the model's trainging and test.\n",
    "        optimizer (string): This string is the optimization function used in the model's trainging and test.\n",
    "        epochs (int): This is int is the number of epochs to use in traning the model.\n",
    "        X_train (array): This data is the feature data will be used to train the model.\n",
    "        y_train (array): This data is the label data will be used to train the model.\n",
    "        X_test (array): This data is the feature data will be used to test the model.\n",
    "        y_test (array): This data is the label data will be used to test the model.\n",
    "        activation (string): This is the function that is required between matrix.\n",
    "        layerNumber (int): How many layers to put into the model.\n",
    "        modelName (string): The name of the model to save the model and loss functions.\n",
    "        patience (int): The max number of times the epochs can go without improvement in the loss function.\n",
    "        customBatchSize (int): Batch sizes of the data to use in the model.\n",
    "\n",
    "        Returns:\n",
    "        model (array): features in shape ready for LSTM training or LSTM predictions.\n",
    "        n_nuerons (array): label ready for LSTM training or LSTM predictions.\n",
    "\n",
    "        Notes: \n",
    "\n",
    "        '''\n",
    "        #####################################\n",
    "        #Reset the backend for the next iteration (rerun the model)\n",
    "        tf.keras.backend.clear_session()\n",
    "        #####################################\n",
    "\n",
    "        # Initialize the model\n",
    "        model = self.model\n",
    "\n",
    "        # Model with n_neurons = inputshape Timestamps, each with x_train.shape[2] variables\n",
    "        #n_neurons = self.X_train.shape[1] * self.X_train.shape[2]\n",
    "    \n",
    "        n_neurons = round(self.X_train.shape[1] / (self.neuron_scale_factor*(self.X_train.shape[2]+1)))\n",
    "        \n",
    "        layerNumber = self.layerNumber+3\n",
    "        \n",
    "        print('Number of look back minutes: {}\\nNumber of features: {}\\nTrainTest split: {}\\nBatches: {}\\nNumber of Neurons: {}\\nLayers: {}'.\n",
    "              format(self.X_train.shape[1], self.X_train.shape[2], self.split, self.customBatchSize, n_neurons, layerNumber))\n",
    "\n",
    "        # These two layers work but not sure if it is a proper LSTM\n",
    "        model.add(LSTM(units=n_neurons, activation='tanh', input_shape=(X_train.shape[1], X_train.shape[2]),\n",
    "                       return_sequences=True, name=self.modelName + \"_Input\"))\n",
    "\n",
    "        if self.layerNumber > 1:\n",
    "            for layer in range(self.layerNumber):\n",
    "                    self.layerName = self.modelName+\"_\"+str(layer)\n",
    "                    if layer < self.layerNumber:\n",
    "                        model.add(LSTM(units=n_neurons, activation=self.activation, \n",
    "                                       return_sequences=True, name =  self.layerName))\n",
    "                    elif layer == self.layerNumber:\n",
    "                        self.layerName = self.modelName+\"_\"+str(layer)\n",
    "                        model.add(LSTM(units=n_neurons, activation=self.activation, \n",
    "                                       return_sequences=False, name =  self.layerName))\n",
    "\n",
    "        model.add(Dropout(0.20))\n",
    "        model.add(Dense(y_train.shape[1]))\n",
    "\n",
    "        model.compile(optimizer=self.optimizer, loss=self.loss,\n",
    "                      metrics=[metrics_tf.mean_squared_error,\n",
    "                               metrics_tf.mean_absolute_error, \n",
    "                               metrics_tf.mean_absolute_percentage_error])\n",
    "\n",
    "        model.summary()\n",
    "        plot_model(model, show_shapes=False)\n",
    "        return model, n_neurons\n",
    "    \n",
    "    def trainModel(self):\n",
    "        '''This function takes model and add additional callbacks into the model.  Here the model is also\n",
    "        saved along with the logs of the model during the training process. The model is saved and if a better\n",
    "        model comes along it is saved and overwrites the model.  This only happens on each model and does not\n",
    "        overwrite other models.  Patience is added to the callbacks to stop the training early if no improvement.\n",
    "        Validation data is added to the model to validate the trained model against test data.\n",
    "\n",
    "        Args:\n",
    "        They are brought in when the class is called an brought into this function.\n",
    "\n",
    "        Returns:\n",
    "        history (model): returns a model after training through the number of epochs.\n",
    "\n",
    "        Notes: \n",
    "        '''\n",
    "        es = EarlyStopping(monitor='val_loss', min_delta=1e-10, patience=self.patience, verbose=1)\n",
    "        rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=self.patience, verbose=1)\n",
    "        #https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint\n",
    "        modelName = self.modelName +'.h5'\n",
    "        saveName = os.path.join(self.model_save_path, modelName)\n",
    "        mcp = ModelCheckpoint(filepath=saveName, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        \n",
    "        # Save logs of callbacks\n",
    "        logdir=os.path.join(self.logs_save_path, (datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")+self.modelName))\n",
    "        tb = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n",
    "        \n",
    "        # fit the model\n",
    "        history = self.model.fit(self.X_train, self.y_train, epochs=self.epochs, batch_size=self.customBatchSize, \n",
    "                            validation_split=0.1, verbose=1, callbacks=[es, rlr, mcp, tb], \n",
    "                            validation_data=(X_test, y_test))\n",
    "\n",
    "        return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1861cc89",
   "metadata": {},
   "source": [
    "## User Variables\n",
    "\n",
    "Here is the inital variables that are needed later in selecting our stock to use, spliting the data and the discrete time inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfc943c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:19.296478Z",
     "start_time": "2021-11-07T11:22:19.282515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Stock symbol we will be using to train our model\n",
    "symbol = \"MNST\"\n",
    "# Past look back minutes to train and amount of futrue minutes to predict\n",
    "lookback_minutes = 360\n",
    "prediction_minutes = 10 # AKA timesteps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34667bf9",
   "metadata": {},
   "source": [
    "## LSTM Model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8288265c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:19.327431Z",
     "start_time": "2021-11-07T11:22:19.313471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split amount for train and test\n",
    "#train_split \" : [0.50, 0.70, 0.90]\n",
    "#ambitious train_split = [0.50, 0.60, 0.70, 0.80, 0.90]\n",
    "\n",
    "#50\n",
    "LSTM_1_dict ={\n",
    "\n",
    "\"train_split\" : 0.50, \n",
    "\"custom_batch_size\" : 64, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_2_dict ={\n",
    "\n",
    "\"train_split\" : 0.50, \n",
    "\"custom_batch_size\" : 128, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_3_dict ={\n",
    "\n",
    "\"train_split\" : 0.50, \n",
    "\"custom_batch_size\" : 256, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "#70\n",
    "LSTM_4_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 64, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_5_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 128, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_6_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 256, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "#90\n",
    "LSTM_7_dict ={\n",
    "\n",
    "\"train_split\" : 0.90, \n",
    "\"custom_batch_size\" : 64, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_8_dict ={\n",
    "\n",
    "\"train_split\" : 0.90, \n",
    "\"custom_batch_size\" : 128, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_9_dict ={\n",
    "\n",
    "\"train_split\" : 0.90, \n",
    "\"custom_batch_size\" : 256, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 3,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "#70_4_Layers\n",
    "LSTM_10_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 64, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 4,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_11_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 128, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 4,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_12_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 256, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 4,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "#70_5_Layers\n",
    "LSTM_13_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 64, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 5,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_14_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 128, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 5,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_15_dict ={\n",
    "\n",
    "\"train_split\" : 0.70, \n",
    "\"custom_batch_size\" : 256, \n",
    "\"custom_epochs\" : 30,\n",
    "\"LSTMLayers\" : 5,\n",
    "\"neuronScaleFactor\" : 2,\n",
    "\"custom_patience\" : 10\n",
    "}\n",
    "\n",
    "LSTM_dict_list = [LSTM_1_dict,LSTM_2_dict,LSTM_3_dict,LSTM_4_dict,LSTM_5_dict,LSTM_6_dict,\n",
    "                  LSTM_7_dict,LSTM_8_dict,LSTM_9_dict,LSTM_10_dict,LSTM_11_dict,LSTM_12_dict,\n",
    "                  LSTM_13_dict, LSTM_14_dict, LSTM_15_dict ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb49b6b",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5936ec9f",
   "metadata": {},
   "source": [
    " ## Function Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e913c17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:20.608461Z",
     "start_time": "2021-11-07T11:22:19.329391Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>R3</th>\n",
       "      <th>R2</th>\n",
       "      <th>R1</th>\n",
       "      <th>...</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>CFI</th>\n",
       "      <th>WOBV</th>\n",
       "      <th>OBV</th>\n",
       "      <th>KC_UPPER</th>\n",
       "      <th>KC_LOWER</th>\n",
       "      <th>kijun</th>\n",
       "      <th>senkou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2020-10-15 09:30:00</td>\n",
       "      <td>81.83</td>\n",
       "      <td>82.495</td>\n",
       "      <td>81.740</td>\n",
       "      <td>81.900</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161408</td>\n",
       "      <td>19445.429659</td>\n",
       "      <td>20785.085</td>\n",
       "      <td>22077.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2020-10-15 09:32:00</td>\n",
       "      <td>81.71</td>\n",
       "      <td>81.720</td>\n",
       "      <td>81.710</td>\n",
       "      <td>81.720</td>\n",
       "      <td>105.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161367</td>\n",
       "      <td>19863.457860</td>\n",
       "      <td>20766.185</td>\n",
       "      <td>21972.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2020-10-15 09:33:00</td>\n",
       "      <td>81.99</td>\n",
       "      <td>82.005</td>\n",
       "      <td>81.990</td>\n",
       "      <td>82.005</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161361</td>\n",
       "      <td>20016.599152</td>\n",
       "      <td>20770.460</td>\n",
       "      <td>21987.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2020-10-15 09:34:00</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.950</td>\n",
       "      <td>81.870</td>\n",
       "      <td>81.950</td>\n",
       "      <td>300.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161248</td>\n",
       "      <td>20138.896573</td>\n",
       "      <td>20753.960</td>\n",
       "      <td>21687.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2020-10-15 09:35:00</td>\n",
       "      <td>81.99</td>\n",
       "      <td>81.990</td>\n",
       "      <td>81.745</td>\n",
       "      <td>81.745</td>\n",
       "      <td>45.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161231</td>\n",
       "      <td>20237.280827</td>\n",
       "      <td>20744.735</td>\n",
       "      <td>21642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77378</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2021-10-14 15:55:00</td>\n",
       "      <td>85.50</td>\n",
       "      <td>85.555</td>\n",
       "      <td>85.480</td>\n",
       "      <td>85.495</td>\n",
       "      <td>3772.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.851734</td>\n",
       "      <td>-310.637706</td>\n",
       "      <td>-9.605</td>\n",
       "      <td>-20005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77379</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2021-10-14 15:56:00</td>\n",
       "      <td>85.51</td>\n",
       "      <td>85.530</td>\n",
       "      <td>85.435</td>\n",
       "      <td>85.435</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.848557</td>\n",
       "      <td>-282.923584</td>\n",
       "      <td>-93.485</td>\n",
       "      <td>-21403.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77380</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2021-10-14 15:57:00</td>\n",
       "      <td>85.47</td>\n",
       "      <td>85.520</td>\n",
       "      <td>85.450</td>\n",
       "      <td>85.520</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.843315</td>\n",
       "      <td>-220.638392</td>\n",
       "      <td>124.370</td>\n",
       "      <td>-18840.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77381</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2021-10-14 15:58:00</td>\n",
       "      <td>85.50</td>\n",
       "      <td>85.515</td>\n",
       "      <td>85.480</td>\n",
       "      <td>85.500</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.837784</td>\n",
       "      <td>-179.870509</td>\n",
       "      <td>68.310</td>\n",
       "      <td>-21643.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77382</th>\n",
       "      <td>MNST</td>\n",
       "      <td>2021-10-14 15:59:00</td>\n",
       "      <td>85.49</td>\n",
       "      <td>85.600</td>\n",
       "      <td>85.490</td>\n",
       "      <td>85.560</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.834170</td>\n",
       "      <td>-122.264059</td>\n",
       "      <td>201.690</td>\n",
       "      <td>-19420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4350</td>\n",
       "      <td>85.5875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77383 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Symbol                Date   Open    High     Low   Close  Volume  \\\n",
       "0       MNST 2020-10-15 09:30:00  81.83  82.495  81.740  81.900  1701.0   \n",
       "1       MNST 2020-10-15 09:32:00  81.71  81.720  81.710  81.720   105.0   \n",
       "2       MNST 2020-10-15 09:33:00  81.99  82.005  81.990  82.005    15.0   \n",
       "3       MNST 2020-10-15 09:34:00  81.88  81.950  81.870  81.950   300.0   \n",
       "4       MNST 2020-10-15 09:35:00  81.99  81.990  81.745  81.745    45.0   \n",
       "...      ...                 ...    ...     ...     ...     ...     ...   \n",
       "77378   MNST 2021-10-14 15:55:00  85.50  85.555  85.480  85.495  3772.0   \n",
       "77379   MNST 2021-10-14 15:56:00  85.51  85.530  85.435  85.435  1398.0   \n",
       "77380   MNST 2021-10-14 15:57:00  85.47  85.520  85.450  85.520  2563.0   \n",
       "77381   MNST 2021-10-14 15:58:00  85.50  85.515  85.480  85.500  2803.0   \n",
       "77382   MNST 2021-10-14 15:59:00  85.49  85.600  85.490  85.560  2223.0   \n",
       "\n",
       "              R3         R2         R1  ...         S2         S3       VWAP  \\\n",
       "0      83.863333  83.246667  82.033333  ...  79.586667  78.373333  90.161408   \n",
       "1      83.863333  83.246667  82.033333  ...  79.586667  78.373333  90.161367   \n",
       "2      83.863333  83.246667  82.033333  ...  79.586667  78.373333  90.161361   \n",
       "3      83.863333  83.246667  82.033333  ...  79.586667  78.373333  90.161248   \n",
       "4      83.863333  83.246667  82.033333  ...  79.586667  78.373333  90.161231   \n",
       "...          ...        ...        ...  ...        ...        ...        ...   \n",
       "77378  87.430000  86.940000  86.250000  ...  84.580000  83.890000  85.851734   \n",
       "77379  87.430000  86.940000  86.250000  ...  84.580000  83.890000  85.848557   \n",
       "77380  87.430000  86.940000  86.250000  ...  84.580000  83.890000  85.843315   \n",
       "77381  87.430000  86.940000  86.250000  ...  84.580000  83.890000  85.837784   \n",
       "77382  87.430000  86.940000  86.250000  ...  84.580000  83.890000  85.834170   \n",
       "\n",
       "                CFI       WOBV      OBV  KC_UPPER  KC_LOWER    kijun   senkou  \n",
       "0      19445.429659  20785.085  22077.0         0         0  81.6475  81.0700  \n",
       "1      19863.457860  20766.185  21972.0         0         0  81.6475  81.0700  \n",
       "2      20016.599152  20770.460  21987.0         0         1  81.6475  81.0700  \n",
       "3      20138.896573  20753.960  21687.0         0         1  81.6475  81.0700  \n",
       "4      20237.280827  20744.735  21642.0         0         1  81.6475  81.0700  \n",
       "...             ...        ...      ...       ...       ...      ...      ...  \n",
       "77378   -310.637706     -9.605 -20005.0         0         0  85.4125  85.6050  \n",
       "77379   -282.923584    -93.485 -21403.0         0         1  85.4125  85.6050  \n",
       "77380   -220.638392    124.370 -18840.0         0         1  85.4125  85.5950  \n",
       "77381   -179.870509     68.310 -21643.0         0         1  85.4125  85.5950  \n",
       "77382   -122.264059    201.690 -19420.0         0         0  85.4350  85.5875  \n",
       "\n",
       "[77383 rows x 22 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = Stock(symbol=symbol).getStockData(source='local',user='james')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77defca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:20.624420Z",
     "start_time": "2021-11-07T11:22:20.609464Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = dataTransformer(scaler='StandardScaler', data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd7e4d46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:20.656365Z",
     "start_time": "2021-11-07T11:22:20.625382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>R3</th>\n",
       "      <th>R2</th>\n",
       "      <th>R1</th>\n",
       "      <th>PP</th>\n",
       "      <th>...</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>CFI</th>\n",
       "      <th>WOBV</th>\n",
       "      <th>OBV</th>\n",
       "      <th>KC_UPPER</th>\n",
       "      <th>KC_LOWER</th>\n",
       "      <th>kijun</th>\n",
       "      <th>senkou</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-10-15 09:30:00</td>\n",
       "      <td>81.83</td>\n",
       "      <td>82.495</td>\n",
       "      <td>81.740</td>\n",
       "      <td>81.900</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161408</td>\n",
       "      <td>19445.429659</td>\n",
       "      <td>20785.085</td>\n",
       "      <td>22077.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-10-15 09:32:00</td>\n",
       "      <td>81.71</td>\n",
       "      <td>81.720</td>\n",
       "      <td>81.710</td>\n",
       "      <td>81.720</td>\n",
       "      <td>105.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161367</td>\n",
       "      <td>19863.457860</td>\n",
       "      <td>20766.185</td>\n",
       "      <td>21972.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-10-15 09:33:00</td>\n",
       "      <td>81.99</td>\n",
       "      <td>82.005</td>\n",
       "      <td>81.990</td>\n",
       "      <td>82.005</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161361</td>\n",
       "      <td>20016.599152</td>\n",
       "      <td>20770.460</td>\n",
       "      <td>21987.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-10-15 09:34:00</td>\n",
       "      <td>81.88</td>\n",
       "      <td>81.950</td>\n",
       "      <td>81.870</td>\n",
       "      <td>81.950</td>\n",
       "      <td>300.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161248</td>\n",
       "      <td>20138.896573</td>\n",
       "      <td>20753.960</td>\n",
       "      <td>21687.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-10-15 09:35:00</td>\n",
       "      <td>81.99</td>\n",
       "      <td>81.990</td>\n",
       "      <td>81.745</td>\n",
       "      <td>81.745</td>\n",
       "      <td>45.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161231</td>\n",
       "      <td>20237.280827</td>\n",
       "      <td>20744.735</td>\n",
       "      <td>21642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77378</th>\n",
       "      <td>2021-10-14 15:55:00</td>\n",
       "      <td>85.50</td>\n",
       "      <td>85.555</td>\n",
       "      <td>85.480</td>\n",
       "      <td>85.495</td>\n",
       "      <td>3772.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.851734</td>\n",
       "      <td>-310.637706</td>\n",
       "      <td>-9.605</td>\n",
       "      <td>-20005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77379</th>\n",
       "      <td>2021-10-14 15:56:00</td>\n",
       "      <td>85.51</td>\n",
       "      <td>85.530</td>\n",
       "      <td>85.435</td>\n",
       "      <td>85.435</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.848557</td>\n",
       "      <td>-282.923584</td>\n",
       "      <td>-93.485</td>\n",
       "      <td>-21403.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.6050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77380</th>\n",
       "      <td>2021-10-14 15:57:00</td>\n",
       "      <td>85.47</td>\n",
       "      <td>85.520</td>\n",
       "      <td>85.450</td>\n",
       "      <td>85.520</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.843315</td>\n",
       "      <td>-220.638392</td>\n",
       "      <td>124.370</td>\n",
       "      <td>-18840.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77381</th>\n",
       "      <td>2021-10-14 15:58:00</td>\n",
       "      <td>85.50</td>\n",
       "      <td>85.515</td>\n",
       "      <td>85.480</td>\n",
       "      <td>85.500</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.837784</td>\n",
       "      <td>-179.870509</td>\n",
       "      <td>68.310</td>\n",
       "      <td>-21643.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.5950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77382</th>\n",
       "      <td>2021-10-14 15:59:00</td>\n",
       "      <td>85.49</td>\n",
       "      <td>85.600</td>\n",
       "      <td>85.490</td>\n",
       "      <td>85.560</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>...</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.834170</td>\n",
       "      <td>-122.264059</td>\n",
       "      <td>201.690</td>\n",
       "      <td>-19420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4350</td>\n",
       "      <td>85.5875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77383 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Date   Open    High     Low   Close  Volume         R3  \\\n",
       "0     2020-10-15 09:30:00  81.83  82.495  81.740  81.900  1701.0  83.863333   \n",
       "1     2020-10-15 09:32:00  81.71  81.720  81.710  81.720   105.0  83.863333   \n",
       "2     2020-10-15 09:33:00  81.99  82.005  81.990  82.005    15.0  83.863333   \n",
       "3     2020-10-15 09:34:00  81.88  81.950  81.870  81.950   300.0  83.863333   \n",
       "4     2020-10-15 09:35:00  81.99  81.990  81.745  81.745    45.0  83.863333   \n",
       "...                   ...    ...     ...     ...     ...     ...        ...   \n",
       "77378 2021-10-14 15:55:00  85.50  85.555  85.480  85.495  3772.0  87.430000   \n",
       "77379 2021-10-14 15:56:00  85.51  85.530  85.435  85.435  1398.0  87.430000   \n",
       "77380 2021-10-14 15:57:00  85.47  85.520  85.450  85.520  2563.0  87.430000   \n",
       "77381 2021-10-14 15:58:00  85.50  85.515  85.480  85.500  2803.0  87.430000   \n",
       "77382 2021-10-14 15:59:00  85.49  85.600  85.490  85.560  2223.0  87.430000   \n",
       "\n",
       "              R2         R1         PP  ...         S2         S3       VWAP  \\\n",
       "0      83.246667  82.033333  81.416667  ...  79.586667  78.373333  90.161408   \n",
       "1      83.246667  82.033333  81.416667  ...  79.586667  78.373333  90.161367   \n",
       "2      83.246667  82.033333  81.416667  ...  79.586667  78.373333  90.161361   \n",
       "3      83.246667  82.033333  81.416667  ...  79.586667  78.373333  90.161248   \n",
       "4      83.246667  82.033333  81.416667  ...  79.586667  78.373333  90.161231   \n",
       "...          ...        ...        ...  ...        ...        ...        ...   \n",
       "77378  86.940000  86.250000  85.760000  ...  84.580000  83.890000  85.851734   \n",
       "77379  86.940000  86.250000  85.760000  ...  84.580000  83.890000  85.848557   \n",
       "77380  86.940000  86.250000  85.760000  ...  84.580000  83.890000  85.843315   \n",
       "77381  86.940000  86.250000  85.760000  ...  84.580000  83.890000  85.837784   \n",
       "77382  86.940000  86.250000  85.760000  ...  84.580000  83.890000  85.834170   \n",
       "\n",
       "                CFI       WOBV      OBV  KC_UPPER  KC_LOWER    kijun   senkou  \n",
       "0      19445.429659  20785.085  22077.0         0         0  81.6475  81.0700  \n",
       "1      19863.457860  20766.185  21972.0         0         0  81.6475  81.0700  \n",
       "2      20016.599152  20770.460  21987.0         0         1  81.6475  81.0700  \n",
       "3      20138.896573  20753.960  21687.0         0         1  81.6475  81.0700  \n",
       "4      20237.280827  20744.735  21642.0         0         1  81.6475  81.0700  \n",
       "...             ...        ...      ...       ...       ...      ...      ...  \n",
       "77378   -310.637706     -9.605 -20005.0         0         0  85.4125  85.6050  \n",
       "77379   -282.923584    -93.485 -21403.0         0         1  85.4125  85.6050  \n",
       "77380   -220.638392    124.370 -18840.0         0         1  85.4125  85.5950  \n",
       "77381   -179.870509     68.310 -21643.0         0         1  85.4125  85.5950  \n",
       "77382   -122.264059    201.690 -19420.0         0         0  85.4350  85.5875  \n",
       "\n",
       "[77383 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transform.CleanImpute(data=df, impute=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dfd9b19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:20.688266Z",
     "start_time": "2021-11-07T11:22:20.658664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Volume</th>\n",
       "      <th>R3</th>\n",
       "      <th>R2</th>\n",
       "      <th>R1</th>\n",
       "      <th>PP</th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>S3</th>\n",
       "      <th>VWAP</th>\n",
       "      <th>CFI</th>\n",
       "      <th>WOBV</th>\n",
       "      <th>OBV</th>\n",
       "      <th>KC_UPPER</th>\n",
       "      <th>KC_LOWER</th>\n",
       "      <th>kijun</th>\n",
       "      <th>senkou</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-15 09:30:00</th>\n",
       "      <td>81.83</td>\n",
       "      <td>82.495</td>\n",
       "      <td>81.740</td>\n",
       "      <td>1701.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>80.203333</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161408</td>\n",
       "      <td>19445.429659</td>\n",
       "      <td>20785.085</td>\n",
       "      <td>22077.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "      <td>81.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-15 09:32:00</th>\n",
       "      <td>81.71</td>\n",
       "      <td>81.720</td>\n",
       "      <td>81.710</td>\n",
       "      <td>105.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>80.203333</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161367</td>\n",
       "      <td>19863.457860</td>\n",
       "      <td>20766.185</td>\n",
       "      <td>21972.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "      <td>81.720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-15 09:33:00</th>\n",
       "      <td>81.99</td>\n",
       "      <td>82.005</td>\n",
       "      <td>81.990</td>\n",
       "      <td>15.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>80.203333</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161361</td>\n",
       "      <td>20016.599152</td>\n",
       "      <td>20770.460</td>\n",
       "      <td>21987.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "      <td>82.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-15 09:34:00</th>\n",
       "      <td>81.88</td>\n",
       "      <td>81.950</td>\n",
       "      <td>81.870</td>\n",
       "      <td>300.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>80.203333</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161248</td>\n",
       "      <td>20138.896573</td>\n",
       "      <td>20753.960</td>\n",
       "      <td>21687.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "      <td>81.950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-15 09:35:00</th>\n",
       "      <td>81.99</td>\n",
       "      <td>81.990</td>\n",
       "      <td>81.745</td>\n",
       "      <td>45.0</td>\n",
       "      <td>83.863333</td>\n",
       "      <td>83.246667</td>\n",
       "      <td>82.033333</td>\n",
       "      <td>81.416667</td>\n",
       "      <td>80.203333</td>\n",
       "      <td>79.586667</td>\n",
       "      <td>78.373333</td>\n",
       "      <td>90.161231</td>\n",
       "      <td>20237.280827</td>\n",
       "      <td>20744.735</td>\n",
       "      <td>21642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>81.6475</td>\n",
       "      <td>81.0700</td>\n",
       "      <td>81.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14 15:55:00</th>\n",
       "      <td>85.50</td>\n",
       "      <td>85.555</td>\n",
       "      <td>85.480</td>\n",
       "      <td>3772.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.851734</td>\n",
       "      <td>-310.637706</td>\n",
       "      <td>-9.605</td>\n",
       "      <td>-20005.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.6050</td>\n",
       "      <td>85.495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14 15:56:00</th>\n",
       "      <td>85.51</td>\n",
       "      <td>85.530</td>\n",
       "      <td>85.435</td>\n",
       "      <td>1398.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.848557</td>\n",
       "      <td>-282.923584</td>\n",
       "      <td>-93.485</td>\n",
       "      <td>-21403.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.6050</td>\n",
       "      <td>85.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14 15:57:00</th>\n",
       "      <td>85.47</td>\n",
       "      <td>85.520</td>\n",
       "      <td>85.450</td>\n",
       "      <td>2563.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.843315</td>\n",
       "      <td>-220.638392</td>\n",
       "      <td>124.370</td>\n",
       "      <td>-18840.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.5950</td>\n",
       "      <td>85.520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14 15:58:00</th>\n",
       "      <td>85.50</td>\n",
       "      <td>85.515</td>\n",
       "      <td>85.480</td>\n",
       "      <td>2803.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.837784</td>\n",
       "      <td>-179.870509</td>\n",
       "      <td>68.310</td>\n",
       "      <td>-21643.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>85.4125</td>\n",
       "      <td>85.5950</td>\n",
       "      <td>85.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-14 15:59:00</th>\n",
       "      <td>85.49</td>\n",
       "      <td>85.600</td>\n",
       "      <td>85.490</td>\n",
       "      <td>2223.0</td>\n",
       "      <td>87.430000</td>\n",
       "      <td>86.940000</td>\n",
       "      <td>86.250000</td>\n",
       "      <td>85.760000</td>\n",
       "      <td>85.070000</td>\n",
       "      <td>84.580000</td>\n",
       "      <td>83.890000</td>\n",
       "      <td>85.834170</td>\n",
       "      <td>-122.264059</td>\n",
       "      <td>201.690</td>\n",
       "      <td>-19420.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>85.4350</td>\n",
       "      <td>85.5875</td>\n",
       "      <td>85.560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77383 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Open    High     Low  Volume         R3         R2  \\\n",
       "Date                                                                       \n",
       "2020-10-15 09:30:00  81.83  82.495  81.740  1701.0  83.863333  83.246667   \n",
       "2020-10-15 09:32:00  81.71  81.720  81.710   105.0  83.863333  83.246667   \n",
       "2020-10-15 09:33:00  81.99  82.005  81.990    15.0  83.863333  83.246667   \n",
       "2020-10-15 09:34:00  81.88  81.950  81.870   300.0  83.863333  83.246667   \n",
       "2020-10-15 09:35:00  81.99  81.990  81.745    45.0  83.863333  83.246667   \n",
       "...                    ...     ...     ...     ...        ...        ...   \n",
       "2021-10-14 15:55:00  85.50  85.555  85.480  3772.0  87.430000  86.940000   \n",
       "2021-10-14 15:56:00  85.51  85.530  85.435  1398.0  87.430000  86.940000   \n",
       "2021-10-14 15:57:00  85.47  85.520  85.450  2563.0  87.430000  86.940000   \n",
       "2021-10-14 15:58:00  85.50  85.515  85.480  2803.0  87.430000  86.940000   \n",
       "2021-10-14 15:59:00  85.49  85.600  85.490  2223.0  87.430000  86.940000   \n",
       "\n",
       "                            R1         PP         S1         S2         S3  \\\n",
       "Date                                                                         \n",
       "2020-10-15 09:30:00  82.033333  81.416667  80.203333  79.586667  78.373333   \n",
       "2020-10-15 09:32:00  82.033333  81.416667  80.203333  79.586667  78.373333   \n",
       "2020-10-15 09:33:00  82.033333  81.416667  80.203333  79.586667  78.373333   \n",
       "2020-10-15 09:34:00  82.033333  81.416667  80.203333  79.586667  78.373333   \n",
       "2020-10-15 09:35:00  82.033333  81.416667  80.203333  79.586667  78.373333   \n",
       "...                        ...        ...        ...        ...        ...   \n",
       "2021-10-14 15:55:00  86.250000  85.760000  85.070000  84.580000  83.890000   \n",
       "2021-10-14 15:56:00  86.250000  85.760000  85.070000  84.580000  83.890000   \n",
       "2021-10-14 15:57:00  86.250000  85.760000  85.070000  84.580000  83.890000   \n",
       "2021-10-14 15:58:00  86.250000  85.760000  85.070000  84.580000  83.890000   \n",
       "2021-10-14 15:59:00  86.250000  85.760000  85.070000  84.580000  83.890000   \n",
       "\n",
       "                          VWAP           CFI       WOBV      OBV  KC_UPPER  \\\n",
       "Date                                                                         \n",
       "2020-10-15 09:30:00  90.161408  19445.429659  20785.085  22077.0         0   \n",
       "2020-10-15 09:32:00  90.161367  19863.457860  20766.185  21972.0         0   \n",
       "2020-10-15 09:33:00  90.161361  20016.599152  20770.460  21987.0         0   \n",
       "2020-10-15 09:34:00  90.161248  20138.896573  20753.960  21687.0         0   \n",
       "2020-10-15 09:35:00  90.161231  20237.280827  20744.735  21642.0         0   \n",
       "...                        ...           ...        ...      ...       ...   \n",
       "2021-10-14 15:55:00  85.851734   -310.637706     -9.605 -20005.0         0   \n",
       "2021-10-14 15:56:00  85.848557   -282.923584    -93.485 -21403.0         0   \n",
       "2021-10-14 15:57:00  85.843315   -220.638392    124.370 -18840.0         0   \n",
       "2021-10-14 15:58:00  85.837784   -179.870509     68.310 -21643.0         0   \n",
       "2021-10-14 15:59:00  85.834170   -122.264059    201.690 -19420.0         0   \n",
       "\n",
       "                     KC_LOWER    kijun   senkou   Close  \n",
       "Date                                                     \n",
       "2020-10-15 09:30:00         0  81.6475  81.0700  81.900  \n",
       "2020-10-15 09:32:00         0  81.6475  81.0700  81.720  \n",
       "2020-10-15 09:33:00         1  81.6475  81.0700  82.005  \n",
       "2020-10-15 09:34:00         1  81.6475  81.0700  81.950  \n",
       "2020-10-15 09:35:00         1  81.6475  81.0700  81.745  \n",
       "...                       ...      ...      ...     ...  \n",
       "2021-10-14 15:55:00         0  85.4125  85.6050  85.495  \n",
       "2021-10-14 15:56:00         1  85.4125  85.6050  85.435  \n",
       "2021-10-14 15:57:00         1  85.4125  85.5950  85.520  \n",
       "2021-10-14 15:58:00         1  85.4125  85.5950  85.500  \n",
       "2021-10-14 15:59:00         0  85.4350  85.5875  85.560  \n",
       "\n",
       "[77383 rows x 20 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = transform.Index_ReorderIndependent(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a228080",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T11:22:20.703229Z",
     "start_time": "2021-11-07T11:22:20.690209Z"
    }
   },
   "outputs": [],
   "source": [
    "n_features = len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dabbcf",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "Train each model 3 times in a loop and save best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba930d00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T14:30:59.757767Z",
     "start_time": "2021-11-07T11:22:20.704206Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Loop different models\n",
    "for LSTM_dict in LSTM_dict_list:\n",
    "    # Split the data based on split size\n",
    "    train, test = transform.GetTrainTest(df, LSTM_dict[\"train_split\"])\n",
    "    # Scale the data\n",
    "    scaled_train, scaled_test, scaler = transform.scaleData(train, test)\n",
    "    \n",
    "    # Transform our dataset into features and label variable and reshaped 3D \n",
    "    # First the Train Dataset\n",
    "    X_train, y_train = transform.reformatDataset(lookback_minutes, prediction_minutes, scaled_train)\n",
    "    # Second the Test Dataset\n",
    "    X_test, y_test = transform.reformatDataset(lookback_minutes, prediction_minutes, scaled_test)\n",
    "    \n",
    "    #modelName = 'LSTM_model_layers_' + str(LSTMLayers+2) + '_train_split_' + str(split)\n",
    "    modelName = 'LSTM_' + str(LSTM_dict[\"LSTMLayers\"]+3) + '_layers_tS_' + str(LSTM_dict[\"train_split\"]) + '_bs_'+str(LSTM_dict[\"custom_batch_size\"])\n",
    "    \n",
    "    # Create the model\n",
    "    model1 = Trainer(loss ='mse', optimizer='adam', epochs=LSTM_dict[\"custom_epochs\"], X_train=X_train, y_train=y_train, \n",
    "                 X_test=X_test, y_test=y_test, activation='tanh', layerNumber=LSTM_dict[\"LSTMLayers\"], modelName=modelName, \n",
    "                 patience=LSTM_dict[\"custom_patience\"], customBatchSize=LSTM_dict[\"custom_batch_size\"], \n",
    "                    neuron_scale_factor = LSTM_dict[\"neuronScaleFactor\"], split = LSTM_dict[\"train_split\"])\n",
    "    model, n_neurons = model1.createModel()\n",
    "    \n",
    "    for i in range(3):\n",
    "        #Fit the model\n",
    "        history = model1.trainModel()\n",
    "    history.model.save('./logs/model/' + modelName + '_Train_3Times.h5')\n",
    "\n",
    "    \n",
    "    # Model Evaluation\n",
    "    evaluation = pd.DataFrame(columns = ['Model', 'Test Size', 'MAE', 'MSE', 'Model Details'])\n",
    "    evaluation.loc[0] = ['LSTM_Train_3times', str(LSTM_dict[\"train_split\"]), min(history.history['mean_absolute_error']), \n",
    "                         min(history.history['mean_squared_error']), modelName]\n",
    "    # Write data to database\n",
    "    engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\".format(host=hostname, db=dbName, user=uname, pw=pwd))\n",
    "    evaluation.to_sql(name='model_evaluation', con=engine, if_exists='append', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac601dbe",
   "metadata": {},
   "source": [
    "## Model Fitting\n",
    "\n",
    "Train models once and see which does better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9d013f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.5\n",
      "Batches: 64\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.5_bs_64_I (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_64_0 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_64_1 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_64_2 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "539/539 [==============================] - 38s 63ms/step - loss: 0.1200 - mean_squared_error: 0.1200 - mean_absolute_error: 0.2336 - mean_absolute_percentage_error: 218.0088 - val_loss: 0.3110 - val_mean_squared_error: 0.3110 - val_mean_absolute_error: 0.4743 - val_mean_absolute_percentage_error: 28.3272\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.31103, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_64.h5\n",
      "Epoch 2/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0626 - mean_squared_error: 0.0626 - mean_absolute_error: 0.1788 - mean_absolute_percentage_error: 192.3298 - val_loss: 0.2634 - val_mean_squared_error: 0.2634 - val_mean_absolute_error: 0.4404 - val_mean_absolute_percentage_error: 26.8451\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.31103 to 0.26336, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_64.h5\n",
      "Epoch 3/30\n",
      "539/539 [==============================] - 33s 60ms/step - loss: 0.0577 - mean_squared_error: 0.0577 - mean_absolute_error: 0.1735 - mean_absolute_percentage_error: 185.8643 - val_loss: 0.2286 - val_mean_squared_error: 0.2286 - val_mean_absolute_error: 0.4046 - val_mean_absolute_percentage_error: 24.6649\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.26336 to 0.22861, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_64.h5\n",
      "Epoch 4/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0548 - mean_squared_error: 0.0548 - mean_absolute_error: 0.1703 - mean_absolute_percentage_error: 189.7137 - val_loss: 0.2247 - val_mean_squared_error: 0.2247 - val_mean_absolute_error: 0.4008 - val_mean_absolute_percentage_error: 24.2798\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.22861 to 0.22473, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_64.h5\n",
      "Epoch 5/30\n",
      "539/539 [==============================] - 32s 60ms/step - loss: 0.0525 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1675 - mean_absolute_percentage_error: 187.4266 - val_loss: 0.2175 - val_mean_squared_error: 0.2175 - val_mean_absolute_error: 0.3976 - val_mean_absolute_percentage_error: 24.3317\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.22473 to 0.21752, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_64.h5\n",
      "Epoch 6/30\n",
      "539/539 [==============================] - 32s 59ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - mean_absolute_error: 0.1654 - mean_absolute_percentage_error: 182.8829 - val_loss: 0.1933 - val_mean_squared_error: 0.1933 - val_mean_absolute_error: 0.3520 - val_mean_absolute_percentage_error: 20.7036\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.21752 to 0.19326, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_64.h5\n",
      "Epoch 7/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0495 - mean_squared_error: 0.0495 - mean_absolute_error: 0.1636 - mean_absolute_percentage_error: 173.2197 - val_loss: 0.2039 - val_mean_squared_error: 0.2039 - val_mean_absolute_error: 0.3762 - val_mean_absolute_percentage_error: 22.8338\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.19326\n",
      "Epoch 8/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0485 - mean_squared_error: 0.0485 - mean_absolute_error: 0.1623 - mean_absolute_percentage_error: 175.4152 - val_loss: 0.2054 - val_mean_squared_error: 0.2054 - val_mean_absolute_error: 0.3765 - val_mean_absolute_percentage_error: 23.0288\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.19326\n",
      "Epoch 9/30\n",
      "539/539 [==============================] - 32s 59ms/step - loss: 0.0474 - mean_squared_error: 0.0474 - mean_absolute_error: 0.1609 - mean_absolute_percentage_error: 173.7830 - val_loss: 0.2015 - val_mean_squared_error: 0.2015 - val_mean_absolute_error: 0.3697 - val_mean_absolute_percentage_error: 22.1686\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.19326\n",
      "Epoch 10/30\n",
      "539/539 [==============================] - 32s 60ms/step - loss: 0.0464 - mean_squared_error: 0.0464 - mean_absolute_error: 0.1592 - mean_absolute_percentage_error: 169.7912 - val_loss: 0.2091 - val_mean_squared_error: 0.2091 - val_mean_absolute_error: 0.3811 - val_mean_absolute_percentage_error: 22.7768\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.19326\n",
      "Epoch 11/30\n",
      "539/539 [==============================] - 33s 60ms/step - loss: 0.0458 - mean_squared_error: 0.0458 - mean_absolute_error: 0.1582 - mean_absolute_percentage_error: 177.6337 - val_loss: 0.2142 - val_mean_squared_error: 0.2142 - val_mean_absolute_error: 0.3887 - val_mean_absolute_percentage_error: 23.0632\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.19326\n",
      "Epoch 12/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - mean_absolute_error: 0.1573 - mean_absolute_percentage_error: 171.8629 - val_loss: 0.2644 - val_mean_squared_error: 0.2644 - val_mean_absolute_error: 0.4492 - val_mean_absolute_percentage_error: 26.8868\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19326\n",
      "Epoch 13/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - mean_absolute_error: 0.1577 - mean_absolute_percentage_error: 174.5206 - val_loss: 0.2654 - val_mean_squared_error: 0.2654 - val_mean_absolute_error: 0.4452 - val_mean_absolute_percentage_error: 26.4717\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19326\n",
      "Epoch 14/30\n",
      "539/539 [==============================] - 33s 61ms/step - loss: 0.0442 - mean_squared_error: 0.0442 - mean_absolute_error: 0.1557 - mean_absolute_percentage_error: 172.2365 - val_loss: 0.2739 - val_mean_squared_error: 0.2739 - val_mean_absolute_error: 0.4558 - val_mean_absolute_percentage_error: 27.3071\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.19326\n",
      "Epoch 15/30\n",
      "539/539 [==============================] - 32s 59ms/step - loss: 0.0437 - mean_squared_error: 0.0437 - mean_absolute_error: 0.1545 - mean_absolute_percentage_error: 168.6191 - val_loss: 0.2834 - val_mean_squared_error: 0.2834 - val_mean_absolute_error: 0.4588 - val_mean_absolute_percentage_error: 27.3827\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19326\n",
      "Epoch 16/30\n",
      "539/539 [==============================] - 32s 59ms/step - loss: 0.0429 - mean_squared_error: 0.0429 - mean_absolute_error: 0.1530 - mean_absolute_percentage_error: 158.4651 - val_loss: 0.3177 - val_mean_squared_error: 0.3177 - val_mean_absolute_error: 0.4938 - val_mean_absolute_percentage_error: 29.6029\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19326\n",
      "Epoch 00016: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.5\n",
      "Batches: 128\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.5_bs_128_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "270/270 [==============================] - 22s 67ms/step - loss: 0.1647 - mean_squared_error: 0.1647 - mean_absolute_error: 0.2755 - mean_absolute_percentage_error: 235.8018 - val_loss: 0.5635 - val_mean_squared_error: 0.5635 - val_mean_absolute_error: 0.6917 - val_mean_absolute_percentage_error: 41.9858\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.56346, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_128.h5\n",
      "Epoch 2/30\n",
      "270/270 [==============================] - 17s 62ms/step - loss: 0.0664 - mean_squared_error: 0.0664 - mean_absolute_error: 0.1836 - mean_absolute_percentage_error: 193.4561 - val_loss: 0.5434 - val_mean_squared_error: 0.5434 - val_mean_absolute_error: 0.6878 - val_mean_absolute_percentage_error: 41.9298\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.56346 to 0.54341, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_128.h5\n",
      "Epoch 3/30\n",
      "270/270 [==============================] - 17s 63ms/step - loss: 0.0603 - mean_squared_error: 0.0603 - mean_absolute_error: 0.1765 - mean_absolute_percentage_error: 187.3140 - val_loss: 0.6390 - val_mean_squared_error: 0.6390 - val_mean_absolute_error: 0.7498 - val_mean_absolute_percentage_error: 45.5020\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.54341\n",
      "Epoch 4/30\n",
      "270/270 [==============================] - 17s 62ms/step - loss: 0.0577 - mean_squared_error: 0.0577 - mean_absolute_error: 0.1736 - mean_absolute_percentage_error: 188.9831 - val_loss: 0.6745 - val_mean_squared_error: 0.6745 - val_mean_absolute_error: 0.7717 - val_mean_absolute_percentage_error: 46.8175\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.54341\n",
      "Epoch 5/30\n",
      "270/270 [==============================] - 17s 64ms/step - loss: 0.0558 - mean_squared_error: 0.0558 - mean_absolute_error: 0.1716 - mean_absolute_percentage_error: 187.4293 - val_loss: 0.7347 - val_mean_squared_error: 0.7347 - val_mean_absolute_error: 0.8059 - val_mean_absolute_percentage_error: 48.8300\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.54341\n",
      "Epoch 6/30\n",
      "270/270 [==============================] - 17s 63ms/step - loss: 0.0543 - mean_squared_error: 0.0543 - mean_absolute_error: 0.1699 - mean_absolute_percentage_error: 190.0485 - val_loss: 0.6583 - val_mean_squared_error: 0.6583 - val_mean_absolute_error: 0.7598 - val_mean_absolute_percentage_error: 45.9046\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.54341\n",
      "Epoch 7/30\n",
      "270/270 [==============================] - 16s 61ms/step - loss: 0.0534 - mean_squared_error: 0.0534 - mean_absolute_error: 0.1689 - mean_absolute_percentage_error: 187.9739 - val_loss: 0.7000 - val_mean_squared_error: 0.7000 - val_mean_absolute_error: 0.7838 - val_mean_absolute_percentage_error: 47.3099\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.54341\n",
      "Epoch 8/30\n",
      "270/270 [==============================] - 17s 61ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - mean_absolute_error: 0.1674 - mean_absolute_percentage_error: 189.6291 - val_loss: 0.7732 - val_mean_squared_error: 0.7732 - val_mean_absolute_error: 0.8289 - val_mean_absolute_percentage_error: 50.2825\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.54341\n",
      "Epoch 9/30\n",
      "270/270 [==============================] - 17s 62ms/step - loss: 0.0514 - mean_squared_error: 0.0514 - mean_absolute_error: 0.1666 - mean_absolute_percentage_error: 186.4281 - val_loss: 0.6647 - val_mean_squared_error: 0.6647 - val_mean_absolute_error: 0.7659 - val_mean_absolute_percentage_error: 46.4111\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.54341\n",
      "Epoch 10/30\n",
      "270/270 [==============================] - 17s 62ms/step - loss: 0.0505 - mean_squared_error: 0.0505 - mean_absolute_error: 0.1653 - mean_absolute_percentage_error: 184.0155 - val_loss: 0.7411 - val_mean_squared_error: 0.7411 - val_mean_absolute_error: 0.8131 - val_mean_absolute_percentage_error: 49.4433\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.54341\n",
      "Epoch 11/30\n",
      "270/270 [==============================] - 17s 63ms/step - loss: 0.0499 - mean_squared_error: 0.0499 - mean_absolute_error: 0.1645 - mean_absolute_percentage_error: 183.3865 - val_loss: 0.6887 - val_mean_squared_error: 0.6887 - val_mean_absolute_error: 0.7796 - val_mean_absolute_percentage_error: 47.1713\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.54341\n",
      "Epoch 12/30\n",
      "270/270 [==============================] - 17s 64ms/step - loss: 0.0493 - mean_squared_error: 0.0493 - mean_absolute_error: 0.1636 - mean_absolute_percentage_error: 179.7178 - val_loss: 0.6671 - val_mean_squared_error: 0.6671 - val_mean_absolute_error: 0.7721 - val_mean_absolute_percentage_error: 47.1273\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.54341\n",
      "Epoch 00012: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.5\n",
      "Batches: 256\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.5_bs_256_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.5_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "135/135 [==============================] - 15s 79ms/step - loss: 0.2012 - mean_squared_error: 0.2012 - mean_absolute_error: 0.3203 - mean_absolute_percentage_error: 287.5073 - val_loss: 0.7932 - val_mean_squared_error: 0.7932 - val_mean_absolute_error: 0.8200 - val_mean_absolute_percentage_error: 49.4026\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79316, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_256.h5\n",
      "Epoch 2/30\n",
      "135/135 [==============================] - 9s 68ms/step - loss: 0.0807 - mean_squared_error: 0.0807 - mean_absolute_error: 0.2057 - mean_absolute_percentage_error: 224.4708 - val_loss: 0.5429 - val_mean_squared_error: 0.5429 - val_mean_absolute_error: 0.6727 - val_mean_absolute_percentage_error: 40.8964\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79316 to 0.54287, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_256.h5\n",
      "Epoch 3/30\n",
      "135/135 [==============================] - 9s 68ms/step - loss: 0.0692 - mean_squared_error: 0.0692 - mean_absolute_error: 0.1901 - mean_absolute_percentage_error: 208.0705 - val_loss: 0.4274 - val_mean_squared_error: 0.4274 - val_mean_absolute_error: 0.5907 - val_mean_absolute_percentage_error: 35.7845\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.54287 to 0.42740, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_256.h5\n",
      "Epoch 4/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0637 - mean_squared_error: 0.0637 - mean_absolute_error: 0.1828 - mean_absolute_percentage_error: 200.6095 - val_loss: 0.3911 - val_mean_squared_error: 0.3911 - val_mean_absolute_error: 0.5610 - val_mean_absolute_percentage_error: 33.9125\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.42740 to 0.39108, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_256.h5\n",
      "Epoch 5/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0606 - mean_squared_error: 0.0606 - mean_absolute_error: 0.1785 - mean_absolute_percentage_error: 194.4685 - val_loss: 0.3996 - val_mean_squared_error: 0.3996 - val_mean_absolute_error: 0.5731 - val_mean_absolute_percentage_error: 34.9025\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.39108\n",
      "Epoch 6/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0584 - mean_squared_error: 0.0584 - mean_absolute_error: 0.1754 - mean_absolute_percentage_error: 190.8499 - val_loss: 0.4261 - val_mean_squared_error: 0.4261 - val_mean_absolute_error: 0.5927 - val_mean_absolute_percentage_error: 35.8809\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.39108\n",
      "Epoch 7/30\n",
      "135/135 [==============================] - 9s 68ms/step - loss: 0.0565 - mean_squared_error: 0.0565 - mean_absolute_error: 0.1727 - mean_absolute_percentage_error: 189.3013 - val_loss: 0.4108 - val_mean_squared_error: 0.4108 - val_mean_absolute_error: 0.5803 - val_mean_absolute_percentage_error: 35.0042\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.39108\n",
      "Epoch 8/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0557 - mean_squared_error: 0.0557 - mean_absolute_error: 0.1715 - mean_absolute_percentage_error: 187.2335 - val_loss: 0.3612 - val_mean_squared_error: 0.3612 - val_mean_absolute_error: 0.5386 - val_mean_absolute_percentage_error: 32.5792\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.39108 to 0.36119, saving model to logs/model\\LSTM_6_layers_tS_0.5_bs_256.h5\n",
      "Epoch 9/30\n",
      "135/135 [==============================] - 9s 67ms/step - loss: 0.0550 - mean_squared_error: 0.0550 - mean_absolute_error: 0.1706 - mean_absolute_percentage_error: 185.3448 - val_loss: 0.3873 - val_mean_squared_error: 0.3873 - val_mean_absolute_error: 0.5603 - val_mean_absolute_percentage_error: 33.6653\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.36119\n",
      "Epoch 10/30\n",
      "135/135 [==============================] - 9s 70ms/step - loss: 0.0545 - mean_squared_error: 0.0545 - mean_absolute_error: 0.1701 - mean_absolute_percentage_error: 182.7452 - val_loss: 0.3876 - val_mean_squared_error: 0.3876 - val_mean_absolute_error: 0.5573 - val_mean_absolute_percentage_error: 33.3011\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.36119\n",
      "Epoch 11/30\n",
      "135/135 [==============================] - 9s 67ms/step - loss: 0.0536 - mean_squared_error: 0.0536 - mean_absolute_error: 0.1691 - mean_absolute_percentage_error: 181.5718 - val_loss: 0.4368 - val_mean_squared_error: 0.4368 - val_mean_absolute_error: 0.5975 - val_mean_absolute_percentage_error: 35.7800\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.36119\n",
      "Epoch 12/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0529 - mean_squared_error: 0.0529 - mean_absolute_error: 0.1681 - mean_absolute_percentage_error: 182.9718 - val_loss: 0.4872 - val_mean_squared_error: 0.4872 - val_mean_absolute_error: 0.6337 - val_mean_absolute_percentage_error: 38.0585\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.36119\n",
      "Epoch 13/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0525 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1677 - mean_absolute_percentage_error: 181.7866 - val_loss: 0.4612 - val_mean_squared_error: 0.4612 - val_mean_absolute_error: 0.6173 - val_mean_absolute_percentage_error: 37.1210\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.36119\n",
      "Epoch 14/30\n",
      "135/135 [==============================] - 9s 66ms/step - loss: 0.0518 - mean_squared_error: 0.0518 - mean_absolute_error: 0.1668 - mean_absolute_percentage_error: 179.7904 - val_loss: 0.5276 - val_mean_squared_error: 0.5276 - val_mean_absolute_error: 0.6686 - val_mean_absolute_percentage_error: 40.4165\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.36119\n",
      "Epoch 15/30\n",
      "135/135 [==============================] - 9s 67ms/step - loss: 0.0508 - mean_squared_error: 0.0508 - mean_absolute_error: 0.1654 - mean_absolute_percentage_error: 177.6680 - val_loss: 0.4125 - val_mean_squared_error: 0.4125 - val_mean_absolute_error: 0.5829 - val_mean_absolute_percentage_error: 35.0969\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.36119\n",
      "Epoch 16/30\n",
      "135/135 [==============================] - 9s 67ms/step - loss: 0.0506 - mean_squared_error: 0.0506 - mean_absolute_error: 0.1652 - mean_absolute_percentage_error: 177.6568 - val_loss: 0.4299 - val_mean_squared_error: 0.4299 - val_mean_absolute_error: 0.5984 - val_mean_absolute_percentage_error: 36.0579\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.36119\n",
      "Epoch 17/30\n",
      "135/135 [==============================] - 9s 67ms/step - loss: 0.0494 - mean_squared_error: 0.0494 - mean_absolute_error: 0.1633 - mean_absolute_percentage_error: 176.6758 - val_loss: 0.4097 - val_mean_squared_error: 0.4097 - val_mean_absolute_error: 0.5826 - val_mean_absolute_percentage_error: 35.0636\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.36119\n",
      "Epoch 18/30\n",
      "135/135 [==============================] - 9s 68ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - mean_absolute_error: 0.1645 - mean_absolute_percentage_error: 183.5897 - val_loss: 0.3988 - val_mean_squared_error: 0.3988 - val_mean_absolute_error: 0.5781 - val_mean_absolute_percentage_error: 35.0601\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.36119\n",
      "Epoch 00018: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 64\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.7_bs_64_I (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_64_0 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_64_1 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_64_2 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "757/757 [==============================] - 51s 62ms/step - loss: 0.1308 - mean_squared_error: 0.1308 - mean_absolute_error: 0.2402 - mean_absolute_percentage_error: 394.2999 - val_loss: 0.0289 - val_mean_squared_error: 0.0289 - val_mean_absolute_error: 0.1303 - val_mean_absolute_percentage_error: 80.4190\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02892, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_64.h5\n",
      "Epoch 2/30\n",
      "757/757 [==============================] - 46s 60ms/step - loss: 0.0695 - mean_squared_error: 0.0695 - mean_absolute_error: 0.1870 - mean_absolute_percentage_error: 361.4808 - val_loss: 0.0421 - val_mean_squared_error: 0.0421 - val_mean_absolute_error: 0.1666 - val_mean_absolute_percentage_error: 103.3623\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02892\n",
      "Epoch 3/30\n",
      "757/757 [==============================] - 46s 60ms/step - loss: 0.0636 - mean_squared_error: 0.0636 - mean_absolute_error: 0.1805 - mean_absolute_percentage_error: 332.8233 - val_loss: 0.0517 - val_mean_squared_error: 0.0517 - val_mean_absolute_error: 0.1858 - val_mean_absolute_percentage_error: 116.8171\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02892\n",
      "Epoch 4/30\n",
      "757/757 [==============================] - 46s 61ms/step - loss: 0.0603 - mean_squared_error: 0.0603 - mean_absolute_error: 0.1766 - mean_absolute_percentage_error: 318.7775 - val_loss: 0.0522 - val_mean_squared_error: 0.0522 - val_mean_absolute_error: 0.1863 - val_mean_absolute_percentage_error: 120.0599\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02892\n",
      "Epoch 5/30\n",
      "757/757 [==============================] - 46s 61ms/step - loss: 0.0579 - mean_squared_error: 0.0579 - mean_absolute_error: 0.1739 - mean_absolute_percentage_error: 309.0410 - val_loss: 0.0671 - val_mean_squared_error: 0.0671 - val_mean_absolute_error: 0.2136 - val_mean_absolute_percentage_error: 136.8216\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02892\n",
      "Epoch 6/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "757/757 [==============================] - 45s 59ms/step - loss: 0.0561 - mean_squared_error: 0.0561 - mean_absolute_error: 0.1717 - mean_absolute_percentage_error: 302.7613 - val_loss: 0.0539 - val_mean_squared_error: 0.0539 - val_mean_absolute_error: 0.1848 - val_mean_absolute_percentage_error: 129.4604\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02892\n",
      "Epoch 7/30\n",
      "757/757 [==============================] - 46s 61ms/step - loss: 0.0550 - mean_squared_error: 0.0550 - mean_absolute_error: 0.1706 - mean_absolute_percentage_error: 305.0388 - val_loss: 0.0584 - val_mean_squared_error: 0.0584 - val_mean_absolute_error: 0.1968 - val_mean_absolute_percentage_error: 130.6238\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02892\n",
      "Epoch 8/30\n",
      "757/757 [==============================] - 47s 62ms/step - loss: 0.0544 - mean_squared_error: 0.0544 - mean_absolute_error: 0.1698 - mean_absolute_percentage_error: 304.6365 - val_loss: 0.0499 - val_mean_squared_error: 0.0499 - val_mean_absolute_error: 0.1812 - val_mean_absolute_percentage_error: 122.3369\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02892\n",
      "Epoch 9/30\n",
      "757/757 [==============================] - 46s 61ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - mean_absolute_error: 0.1685 - mean_absolute_percentage_error: 292.9990 - val_loss: 0.0548 - val_mean_squared_error: 0.0548 - val_mean_absolute_error: 0.1897 - val_mean_absolute_percentage_error: 122.6503\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02892\n",
      "Epoch 10/30\n",
      "757/757 [==============================] - 47s 62ms/step - loss: 0.0527 - mean_squared_error: 0.0527 - mean_absolute_error: 0.1677 - mean_absolute_percentage_error: 291.2868 - val_loss: 0.0432 - val_mean_squared_error: 0.0432 - val_mean_absolute_error: 0.1618 - val_mean_absolute_percentage_error: 116.7927\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02892\n",
      "Epoch 11/30\n",
      "757/757 [==============================] - 47s 62ms/step - loss: 0.0519 - mean_squared_error: 0.0519 - mean_absolute_error: 0.1665 - mean_absolute_percentage_error: 286.1324 - val_loss: 0.0784 - val_mean_squared_error: 0.0784 - val_mean_absolute_error: 0.2298 - val_mean_absolute_percentage_error: 116.9549\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02892\n",
      "Epoch 00011: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 128\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.7_bs_128_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "379/379 [==============================] - 30s 67ms/step - loss: 0.1801 - mean_squared_error: 0.1801 - mean_absolute_error: 0.2788 - mean_absolute_percentage_error: 432.7267 - val_loss: 0.0224 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.1103 - val_mean_absolute_percentage_error: 57.4488\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02237, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 2/30\n",
      "379/379 [==============================] - 23s 62ms/step - loss: 0.0776 - mean_squared_error: 0.0776 - mean_absolute_error: 0.1957 - mean_absolute_percentage_error: 356.4543 - val_loss: 0.0280 - val_mean_squared_error: 0.0280 - val_mean_absolute_error: 0.1320 - val_mean_absolute_percentage_error: 70.7277\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02237\n",
      "Epoch 3/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0699 - mean_squared_error: 0.0699 - mean_absolute_error: 0.1867 - mean_absolute_percentage_error: 365.0087 - val_loss: 0.0264 - val_mean_squared_error: 0.0264 - val_mean_absolute_error: 0.1304 - val_mean_absolute_percentage_error: 67.6720\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02237\n",
      "Epoch 4/30\n",
      "379/379 [==============================] - 23s 61ms/step - loss: 0.0652 - mean_squared_error: 0.0652 - mean_absolute_error: 0.1818 - mean_absolute_percentage_error: 335.8704 - val_loss: 0.0268 - val_mean_squared_error: 0.0268 - val_mean_absolute_error: 0.1326 - val_mean_absolute_percentage_error: 69.9638\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02237\n",
      "Epoch 5/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0625 - mean_squared_error: 0.0625 - mean_absolute_error: 0.1789 - mean_absolute_percentage_error: 344.6736 - val_loss: 0.0208 - val_mean_squared_error: 0.0208 - val_mean_absolute_error: 0.1145 - val_mean_absolute_percentage_error: 55.9013\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02237 to 0.02078, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 6/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0614 - mean_squared_error: 0.0614 - mean_absolute_error: 0.1777 - mean_absolute_percentage_error: 326.1638 - val_loss: 0.0253 - val_mean_squared_error: 0.0253 - val_mean_absolute_error: 0.1295 - val_mean_absolute_percentage_error: 68.5358\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02078\n",
      "Epoch 7/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0597 - mean_squared_error: 0.0597 - mean_absolute_error: 0.1758 - mean_absolute_percentage_error: 324.0497 - val_loss: 0.0214 - val_mean_squared_error: 0.0214 - val_mean_absolute_error: 0.1177 - val_mean_absolute_percentage_error: 64.0001\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02078\n",
      "Epoch 8/30\n",
      "379/379 [==============================] - 23s 62ms/step - loss: 0.0587 - mean_squared_error: 0.0587 - mean_absolute_error: 0.1749 - mean_absolute_percentage_error: 312.4758 - val_loss: 0.0224 - val_mean_squared_error: 0.0224 - val_mean_absolute_error: 0.1205 - val_mean_absolute_percentage_error: 67.3667\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02078\n",
      "Epoch 9/30\n",
      "379/379 [==============================] - 23s 62ms/step - loss: 0.0576 - mean_squared_error: 0.0576 - mean_absolute_error: 0.1735 - mean_absolute_percentage_error: 316.7670 - val_loss: 0.0258 - val_mean_squared_error: 0.0258 - val_mean_absolute_error: 0.1317 - val_mean_absolute_percentage_error: 74.5644\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02078\n",
      "Epoch 10/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0567 - mean_squared_error: 0.0567 - mean_absolute_error: 0.1726 - mean_absolute_percentage_error: 310.9616 - val_loss: 0.0197 - val_mean_squared_error: 0.0197 - val_mean_absolute_error: 0.1123 - val_mean_absolute_percentage_error: 68.1597\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.02078 to 0.01973, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 11/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0565 - mean_squared_error: 0.0565 - mean_absolute_error: 0.1726 - mean_absolute_percentage_error: 290.3591 - val_loss: 0.0221 - val_mean_squared_error: 0.0221 - val_mean_absolute_error: 0.1204 - val_mean_absolute_percentage_error: 75.6574\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01973\n",
      "Epoch 12/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0554 - mean_squared_error: 0.0554 - mean_absolute_error: 0.1713 - mean_absolute_percentage_error: 294.2783 - val_loss: 0.0177 - val_mean_squared_error: 0.0177 - val_mean_absolute_error: 0.1048 - val_mean_absolute_percentage_error: 69.1898\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.01973 to 0.01769, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 13/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0546 - mean_squared_error: 0.0546 - mean_absolute_error: 0.1703 - mean_absolute_percentage_error: 292.1621 - val_loss: 0.0162 - val_mean_squared_error: 0.0162 - val_mean_absolute_error: 0.0994 - val_mean_absolute_percentage_error: 63.7900\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.01769 to 0.01624, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 14/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0542 - mean_squared_error: 0.0542 - mean_absolute_error: 0.1700 - mean_absolute_percentage_error: 288.6424 - val_loss: 0.0139 - val_mean_squared_error: 0.0139 - val_mean_absolute_error: 0.0901 - val_mean_absolute_percentage_error: 62.3916\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.01624 to 0.01386, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 15/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - mean_absolute_error: 0.1687 - mean_absolute_percentage_error: 292.2015 - val_loss: 0.0148 - val_mean_squared_error: 0.0148 - val_mean_absolute_error: 0.0937 - val_mean_absolute_percentage_error: 66.8496\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01386\n",
      "Epoch 16/30\n",
      "379/379 [==============================] - 24s 62ms/step - loss: 0.0528 - mean_squared_error: 0.0528 - mean_absolute_error: 0.1679 - mean_absolute_percentage_error: 288.1876 - val_loss: 0.0163 - val_mean_squared_error: 0.0163 - val_mean_absolute_error: 0.0994 - val_mean_absolute_percentage_error: 67.8246\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01386\n",
      "Epoch 17/30\n",
      "379/379 [==============================] - 23s 62ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - mean_absolute_error: 0.1668 - mean_absolute_percentage_error: 281.7035 - val_loss: 0.0180 - val_mean_squared_error: 0.0180 - val_mean_absolute_error: 0.1054 - val_mean_absolute_percentage_error: 72.2160\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01386\n",
      "Epoch 18/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0522 - mean_squared_error: 0.0522 - mean_absolute_error: 0.1670 - mean_absolute_percentage_error: 294.3086 - val_loss: 0.0159 - val_mean_squared_error: 0.0159 - val_mean_absolute_error: 0.0969 - val_mean_absolute_percentage_error: 69.2912\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01386\n",
      "Epoch 19/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0514 - mean_squared_error: 0.0514 - mean_absolute_error: 0.1656 - mean_absolute_percentage_error: 300.8868 - val_loss: 0.0133 - val_mean_squared_error: 0.0133 - val_mean_absolute_error: 0.0889 - val_mean_absolute_percentage_error: 64.4291\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.01386 to 0.01330, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_128.h5\n",
      "Epoch 20/30\n",
      "379/379 [==============================] - 25s 65ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - mean_absolute_error: 0.1645 - mean_absolute_percentage_error: 287.9155 - val_loss: 0.0174 - val_mean_squared_error: 0.0174 - val_mean_absolute_error: 0.1030 - val_mean_absolute_percentage_error: 74.2753\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01330\n",
      "Epoch 21/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0506 - mean_squared_error: 0.0506 - mean_absolute_error: 0.1643 - mean_absolute_percentage_error: 288.4447 - val_loss: 0.0178 - val_mean_squared_error: 0.0178 - val_mean_absolute_error: 0.1036 - val_mean_absolute_percentage_error: 73.9575\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01330\n",
      "Epoch 22/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0503 - mean_squared_error: 0.0503 - mean_absolute_error: 0.1638 - mean_absolute_percentage_error: 288.9711 - val_loss: 0.0144 - val_mean_squared_error: 0.0144 - val_mean_absolute_error: 0.0920 - val_mean_absolute_percentage_error: 68.0877\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01330\n",
      "Epoch 23/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0499 - mean_squared_error: 0.0499 - mean_absolute_error: 0.1631 - mean_absolute_percentage_error: 289.3365 - val_loss: 0.0165 - val_mean_squared_error: 0.0165 - val_mean_absolute_error: 0.1003 - val_mean_absolute_percentage_error: 70.5381\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01330\n",
      "Epoch 24/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0504 - mean_squared_error: 0.0504 - mean_absolute_error: 0.1641 - mean_absolute_percentage_error: 285.2046 - val_loss: 0.0183 - val_mean_squared_error: 0.0183 - val_mean_absolute_error: 0.1058 - val_mean_absolute_percentage_error: 78.6609\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01330\n",
      "Epoch 25/30\n",
      "379/379 [==============================] - 24s 63ms/step - loss: 0.0501 - mean_squared_error: 0.0501 - mean_absolute_error: 0.1635 - mean_absolute_percentage_error: 297.9239 - val_loss: 0.0211 - val_mean_squared_error: 0.0211 - val_mean_absolute_error: 0.1167 - val_mean_absolute_percentage_error: 76.5537\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.01330\n",
      "Epoch 26/30\n",
      "379/379 [==============================] - 24s 64ms/step - loss: 0.0502 - mean_squared_error: 0.0502 - mean_absolute_error: 0.1638 - mean_absolute_percentage_error: 289.0226 - val_loss: 0.0162 - val_mean_squared_error: 0.0162 - val_mean_absolute_error: 0.0994 - val_mean_absolute_percentage_error: 68.3976\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01330\n",
      "Epoch 27/30\n",
      "379/379 [==============================] - 24s 65ms/step - loss: 0.0519 - mean_squared_error: 0.0519 - mean_absolute_error: 0.1661 - mean_absolute_percentage_error: 301.2621 - val_loss: 0.0172 - val_mean_squared_error: 0.0172 - val_mean_absolute_error: 0.1016 - val_mean_absolute_percentage_error: 75.4261\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.01330\n",
      "Epoch 28/30\n",
      "379/379 [==============================] - 23s 62ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - mean_absolute_error: 0.1642 - mean_absolute_percentage_error: 283.7090 - val_loss: 0.0152 - val_mean_squared_error: 0.0152 - val_mean_absolute_error: 0.0940 - val_mean_absolute_percentage_error: 72.3203\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.01330\n",
      "Epoch 29/30\n",
      "379/379 [==============================] - 23s 62ms/step - loss: 0.0500 - mean_squared_error: 0.0500 - mean_absolute_error: 0.1629 - mean_absolute_percentage_error: 280.3935 - val_loss: 0.0169 - val_mean_squared_error: 0.0169 - val_mean_absolute_error: 0.1016 - val_mean_absolute_percentage_error: 75.0202\n",
      "\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.01330\n",
      "Epoch 00029: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 256\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.7_bs_256_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "190/190 [==============================] - 18s 75ms/step - loss: 0.3001 - mean_squared_error: 0.3001 - mean_absolute_error: 0.3713 - mean_absolute_percentage_error: 485.5415 - val_loss: 0.0326 - val_mean_squared_error: 0.0326 - val_mean_absolute_error: 0.1398 - val_mean_absolute_percentage_error: 79.4929\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03265, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_256.h5\n",
      "Epoch 2/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0931 - mean_squared_error: 0.0931 - mean_absolute_error: 0.2123 - mean_absolute_percentage_error: 397.2895 - val_loss: 0.0307 - val_mean_squared_error: 0.0307 - val_mean_absolute_error: 0.1351 - val_mean_absolute_percentage_error: 81.0486\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03265 to 0.03071, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_256.h5\n",
      "Epoch 3/30\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0817 - mean_squared_error: 0.0817 - mean_absolute_error: 0.1997 - mean_absolute_percentage_error: 368.9072 - val_loss: 0.0275 - val_mean_squared_error: 0.0275 - val_mean_absolute_error: 0.1265 - val_mean_absolute_percentage_error: 79.7788\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03071 to 0.02749, saving model to logs/model\\LSTM_6_layers_tS_0.7_bs_256.h5\n",
      "Epoch 4/30\n",
      "190/190 [==============================] - 13s 71ms/step - loss: 0.0765 - mean_squared_error: 0.0765 - mean_absolute_error: 0.1940 - mean_absolute_percentage_error: 361.9380 - val_loss: 0.0332 - val_mean_squared_error: 0.0332 - val_mean_absolute_error: 0.1429 - val_mean_absolute_percentage_error: 89.8853\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02749\n",
      "Epoch 5/30\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0734 - mean_squared_error: 0.0734 - mean_absolute_error: 0.1908 - mean_absolute_percentage_error: 354.6009 - val_loss: 0.0329 - val_mean_squared_error: 0.0329 - val_mean_absolute_error: 0.1414 - val_mean_absolute_percentage_error: 91.7456solute_error: 0.1910 - mean_abso\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02749\n",
      "Epoch 6/30\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0704 - mean_squared_error: 0.0704 - mean_absolute_error: 0.1876 - mean_absolute_percentage_error: 358.4742 - val_loss: 0.0314 - val_mean_squared_error: 0.0314 - val_mean_absolute_error: 0.1385 - val_mean_absolute_percentage_error: 89.7885\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02749\n",
      "Epoch 7/30\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.0683 - mean_squared_error: 0.0683 - mean_absolute_error: 0.1860 - mean_absolute_percentage_error: 342.0224 - val_loss: 0.0309 - val_mean_squared_error: 0.0309 - val_mean_absolute_error: 0.1385 - val_mean_absolute_percentage_error: 90.2855\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02749\n",
      "Epoch 8/30\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0652 - mean_squared_error: 0.0652 - mean_absolute_error: 0.1825 - mean_absolute_percentage_error: 350.5277 - val_loss: 0.0292 - val_mean_squared_error: 0.0292 - val_mean_absolute_error: 0.1350 - val_mean_absolute_percentage_error: 88.1886\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02749\n",
      "Epoch 9/30\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.0631 - mean_squared_error: 0.0631 - mean_absolute_error: 0.1804 - mean_absolute_percentage_error: 339.0503 - val_loss: 0.0283 - val_mean_squared_error: 0.0283 - val_mean_absolute_error: 0.1329 - val_mean_absolute_percentage_error: 87.6938\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02749\n",
      "Epoch 10/30\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.0616 - mean_squared_error: 0.0616 - mean_absolute_error: 0.1785 - mean_absolute_percentage_error: 333.5294 - val_loss: 0.0300 - val_mean_squared_error: 0.0300 - val_mean_absolute_error: 0.1387 - val_mean_absolute_percentage_error: 90.8376\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02749\n",
      "Epoch 11/30\n",
      "190/190 [==============================] - 13s 68ms/step - loss: 0.0602 - mean_squared_error: 0.0602 - mean_absolute_error: 0.1770 - mean_absolute_percentage_error: 316.0891 - val_loss: 0.0343 - val_mean_squared_error: 0.0343 - val_mean_absolute_error: 0.1482 - val_mean_absolute_percentage_error: 99.2729\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02749\n",
      "Epoch 12/30\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0617 - mean_squared_error: 0.0617 - mean_absolute_error: 0.1786 - mean_absolute_percentage_error: 320.2865 - val_loss: 0.0295 - val_mean_squared_error: 0.0295 - val_mean_absolute_error: 0.1363 - val_mean_absolute_percentage_error: 92.1917\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02749\n",
      "Epoch 13/30\n",
      "190/190 [==============================] - 13s 69ms/step - loss: 0.0590 - mean_squared_error: 0.0590 - mean_absolute_error: 0.1754 - mean_absolute_percentage_error: 293.2850 - val_loss: 0.0376 - val_mean_squared_error: 0.0376 - val_mean_absolute_error: 0.1552 - val_mean_absolute_percentage_error: 104.9826\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02749\n",
      "Epoch 00013: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.9\n",
      "Batches: 64\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.9_bs_64_I (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_64_0 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_64_1 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_64_2 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "975/975 [==============================] - 65s 63ms/step - loss: 0.0943 - mean_squared_error: 0.0943 - mean_absolute_error: 0.2013 - mean_absolute_percentage_error: 128.3982 - val_loss: 0.4647 - val_mean_squared_error: 0.4647 - val_mean_absolute_error: 0.6317 - val_mean_absolute_percentage_error: 49.1373\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.46473, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 2/30\n",
      "975/975 [==============================] - 60s 62ms/step - loss: 0.0576 - mean_squared_error: 0.0576 - mean_absolute_error: 0.1674 - mean_absolute_percentage_error: 109.4362 - val_loss: 0.5302 - val_mean_squared_error: 0.5302 - val_mean_absolute_error: 0.6616 - val_mean_absolute_percentage_error: 51.9632\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.46473\n",
      "Epoch 3/30\n",
      "975/975 [==============================] - 60s 61ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - mean_absolute_error: 0.1630 - mean_absolute_percentage_error: 99.7105 - val_loss: 0.5375 - val_mean_squared_error: 0.5375 - val_mean_absolute_error: 0.6801 - val_mean_absolute_percentage_error: 53.2165\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.46473\n",
      "Epoch 4/30\n",
      "975/975 [==============================] - 61s 62ms/step - loss: 0.0508 - mean_squared_error: 0.0508 - mean_absolute_error: 0.1600 - mean_absolute_percentage_error: 101.1903 - val_loss: 0.4868 - val_mean_squared_error: 0.4868 - val_mean_absolute_error: 0.6424 - val_mean_absolute_percentage_error: 50.2425\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.46473\n",
      "Epoch 5/30\n",
      "975/975 [==============================] - 59s 61ms/step - loss: 0.0490 - mean_squared_error: 0.0490 - mean_absolute_error: 0.1579 - mean_absolute_percentage_error: 98.4543 - val_loss: 0.4590 - val_mean_squared_error: 0.4590 - val_mean_absolute_error: 0.6083 - val_mean_absolute_percentage_error: 47.6093\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.46473 to 0.45901, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 6/30\n",
      "975/975 [==============================] - 60s 62ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - mean_absolute_error: 0.1567 - mean_absolute_percentage_error: 100.4381 - val_loss: 0.3574 - val_mean_squared_error: 0.3574 - val_mean_absolute_error: 0.5543 - val_mean_absolute_percentage_error: 42.7485\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.45901 to 0.35743, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 7/30\n",
      "975/975 [==============================] - 60s 61ms/step - loss: 0.0467 - mean_squared_error: 0.0467 - mean_absolute_error: 0.1549 - mean_absolute_percentage_error: 100.7257 - val_loss: 0.3842 - val_mean_squared_error: 0.3842 - val_mean_absolute_error: 0.5848 - val_mean_absolute_percentage_error: 44.8981\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.35743\n",
      "Epoch 8/30\n",
      "975/975 [==============================] - 60s 62ms/step - loss: 0.0460 - mean_squared_error: 0.0460 - mean_absolute_error: 0.1538 - mean_absolute_percentage_error: 100.0790 - val_loss: 0.3544 - val_mean_squared_error: 0.3544 - val_mean_absolute_error: 0.5379 - val_mean_absolute_percentage_error: 42.0018\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.35743 to 0.35445, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 9/30\n",
      "975/975 [==============================] - 60s 62ms/step - loss: 0.0452 - mean_squared_error: 0.0452 - mean_absolute_error: 0.1526 - mean_absolute_percentage_error: 98.8706 - val_loss: 0.3425 - val_mean_squared_error: 0.3425 - val_mean_absolute_error: 0.5412 - val_mean_absolute_percentage_error: 42.0130\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.35445 to 0.34254, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 10/30\n",
      "975/975 [==============================] - 59s 61ms/step - loss: 0.0454 - mean_squared_error: 0.0454 - mean_absolute_error: 0.1536 - mean_absolute_percentage_error: 97.5397 - val_loss: 0.2995 - val_mean_squared_error: 0.2995 - val_mean_absolute_error: 0.5026 - val_mean_absolute_percentage_error: 39.0605\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.34254 to 0.29950, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 11/30\n",
      "975/975 [==============================] - 79s 81ms/step - loss: 0.0445 - mean_squared_error: 0.0445 - mean_absolute_error: 0.1519 - mean_absolute_percentage_error: 95.7337 - val_loss: 0.3727 - val_mean_squared_error: 0.3727 - val_mean_absolute_error: 0.5676 - val_mean_absolute_percentage_error: 44.0757\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.29950\n",
      "Epoch 12/30\n",
      "975/975 [==============================] - 108s 110ms/step - loss: 0.0439 - mean_squared_error: 0.0439 - mean_absolute_error: 0.1503 - mean_absolute_percentage_error: 97.8138 - val_loss: 0.3657 - val_mean_squared_error: 0.3657 - val_mean_absolute_error: 0.5623 - val_mean_absolute_percentage_error: 43.6854\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.29950\n",
      "Epoch 13/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0445 - mean_squared_error: 0.0445 - mean_absolute_error: 0.1511 - mean_absolute_percentage_error: 97.7627 - val_loss: 0.3350 - val_mean_squared_error: 0.3350 - val_mean_absolute_error: 0.5249 - val_mean_absolute_percentage_error: 41.0385\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.29950\n",
      "Epoch 14/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0429 - mean_squared_error: 0.0429 - mean_absolute_error: 0.1483 - mean_absolute_percentage_error: 94.3042 - val_loss: 0.3857 - val_mean_squared_error: 0.3857 - val_mean_absolute_error: 0.5630 - val_mean_absolute_percentage_error: 44.0805\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.29950\n",
      "Epoch 15/30\n",
      "975/975 [==============================] - 109s 111ms/step - loss: 0.0425 - mean_squared_error: 0.0425 - mean_absolute_error: 0.1476 - mean_absolute_percentage_error: 94.3394 - val_loss: 0.3596 - val_mean_squared_error: 0.3596 - val_mean_absolute_error: 0.5414 - val_mean_absolute_percentage_error: 42.3637\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.29950\n",
      "Epoch 16/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0426 - mean_squared_error: 0.0426 - mean_absolute_error: 0.1477 - mean_absolute_percentage_error: 91.7126 - val_loss: 0.4112 - val_mean_squared_error: 0.4112 - val_mean_absolute_error: 0.5469 - val_mean_absolute_percentage_error: 43.2080\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.29950\n",
      "Epoch 17/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0424 - mean_squared_error: 0.0424 - mean_absolute_error: 0.1471 - mean_absolute_percentage_error: 93.7516 - val_loss: 0.3591 - val_mean_squared_error: 0.3591 - val_mean_absolute_error: 0.5213 - val_mean_absolute_percentage_error: 41.0870\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.29950\n",
      "Epoch 18/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0428 - mean_squared_error: 0.0428 - mean_absolute_error: 0.1479 - mean_absolute_percentage_error: 94.0199 - val_loss: 0.2345 - val_mean_squared_error: 0.2345 - val_mean_absolute_error: 0.4481 - val_mean_absolute_percentage_error: 34.5421\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.29950 to 0.23452, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 19/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0413 - mean_squared_error: 0.0413 - mean_absolute_error: 0.1453 - mean_absolute_percentage_error: 90.1015 - val_loss: 0.2275 - val_mean_squared_error: 0.2275 - val_mean_absolute_error: 0.4125 - val_mean_absolute_percentage_error: 32.3697\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.23452 to 0.22747, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 20/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0414 - mean_squared_error: 0.0414 - mean_absolute_error: 0.1452 - mean_absolute_percentage_error: 92.2446 - val_loss: 0.2835 - val_mean_squared_error: 0.2835 - val_mean_absolute_error: 0.4657 - val_mean_absolute_percentage_error: 36.5553\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.22747\n",
      "Epoch 21/30\n",
      "975/975 [==============================] - 109s 112ms/step - loss: 0.0419 - mean_squared_error: 0.0419 - mean_absolute_error: 0.1464 - mean_absolute_percentage_error: 92.3807 - val_loss: 0.3057 - val_mean_squared_error: 0.3057 - val_mean_absolute_error: 0.4669 - val_mean_absolute_percentage_error: 36.6805\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.22747\n",
      "Epoch 22/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0416 - mean_squared_error: 0.0416 - mean_absolute_error: 0.1456 - mean_absolute_percentage_error: 91.2316 - val_loss: 0.3349 - val_mean_squared_error: 0.3349 - val_mean_absolute_error: 0.4739 - val_mean_absolute_percentage_error: 37.4036\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.22747\n",
      "Epoch 23/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0423 - mean_squared_error: 0.0423 - mean_absolute_error: 0.1475 - mean_absolute_percentage_error: 91.0269 - val_loss: 0.2487 - val_mean_squared_error: 0.2487 - val_mean_absolute_error: 0.4140 - val_mean_absolute_percentage_error: 32.4970\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.22747\n",
      "Epoch 24/30\n",
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0421 - mean_squared_error: 0.0421 - mean_absolute_error: 0.1472 - mean_absolute_percentage_error: 91.4923 - val_loss: 0.3150 - val_mean_squared_error: 0.3150 - val_mean_absolute_error: 0.4545 - val_mean_absolute_percentage_error: 35.7391\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.22747\n",
      "Epoch 25/30\n",
      "975/975 [==============================] - 109s 112ms/step - loss: 0.0412 - mean_squared_error: 0.0412 - mean_absolute_error: 0.1453 - mean_absolute_percentage_error: 89.1288 - val_loss: 0.2758 - val_mean_squared_error: 0.2758 - val_mean_absolute_error: 0.4449 - val_mean_absolute_percentage_error: 34.8545\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.22747\n",
      "Epoch 26/30\n",
      "975/975 [==============================] - 107s 110ms/step - loss: 0.0423 - mean_squared_error: 0.0423 - mean_absolute_error: 0.1473 - mean_absolute_percentage_error: 93.6728 - val_loss: 0.2393 - val_mean_squared_error: 0.2393 - val_mean_absolute_error: 0.4170 - val_mean_absolute_percentage_error: 32.5782\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.22747\n",
      "Epoch 27/30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975/975 [==============================] - 108s 111ms/step - loss: 0.0414 - mean_squared_error: 0.0414 - mean_absolute_error: 0.1458 - mean_absolute_percentage_error: 92.1178 - val_loss: 0.2552 - val_mean_squared_error: 0.2552 - val_mean_absolute_error: 0.4331 - val_mean_absolute_percentage_error: 33.8528\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.22747\n",
      "Epoch 28/30\n",
      "975/975 [==============================] - 110s 112ms/step - loss: 0.0425 - mean_squared_error: 0.0425 - mean_absolute_error: 0.1483 - mean_absolute_percentage_error: 93.5336 - val_loss: 0.2994 - val_mean_squared_error: 0.2994 - val_mean_absolute_error: 0.4722 - val_mean_absolute_percentage_error: 37.3029\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.22747\n",
      "Epoch 29/30\n",
      "975/975 [==============================] - 109s 112ms/step - loss: 0.0414 - mean_squared_error: 0.0414 - mean_absolute_error: 0.1459 - mean_absolute_percentage_error: 91.3675 - val_loss: 0.1956 - val_mean_squared_error: 0.1956 - val_mean_absolute_error: 0.3764 - val_mean_absolute_percentage_error: 29.5026\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.22747 to 0.19560, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_64.h5\n",
      "Epoch 30/30\n",
      "975/975 [==============================] - 109s 112ms/step - loss: 0.0412 - mean_squared_error: 0.0412 - mean_absolute_error: 0.1453 - mean_absolute_percentage_error: 92.1070 - val_loss: 0.3059 - val_mean_squared_error: 0.3059 - val_mean_absolute_error: 0.4765 - val_mean_absolute_percentage_error: 37.8442\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.19560\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.9\n",
      "Batches: 128\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.9_bs_128_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "488/488 [==============================] - 71s 125ms/step - loss: 0.1126 - mean_squared_error: 0.1126 - mean_absolute_error: 0.2196 - mean_absolute_percentage_error: 141.4692 - val_loss: 0.3277 - val_mean_squared_error: 0.3277 - val_mean_absolute_error: 0.5436 - val_mean_absolute_percentage_error: 41.7124\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.32773, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_128.h5\n",
      "Epoch 2/30\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0624 - mean_squared_error: 0.0624 - mean_absolute_error: 0.1724 - mean_absolute_percentage_error: 115.5902 - val_loss: 0.2259 - val_mean_squared_error: 0.2259 - val_mean_absolute_error: 0.4449 - val_mean_absolute_percentage_error: 34.0010\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.32773 to 0.22589, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_128.h5\n",
      "Epoch 3/30\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0572 - mean_squared_error: 0.0572 - mean_absolute_error: 0.1668 - mean_absolute_percentage_error: 112.2955 - val_loss: 0.2791 - val_mean_squared_error: 0.2791 - val_mean_absolute_error: 0.5003 - val_mean_absolute_percentage_error: 38.4178\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.22589\n",
      "Epoch 4/30\n",
      "488/488 [==============================] - 57s 116ms/step - loss: 0.0543 - mean_squared_error: 0.0543 - mean_absolute_error: 0.1640 - mean_absolute_percentage_error: 108.2473 - val_loss: 0.3201 - val_mean_squared_error: 0.3201 - val_mean_absolute_error: 0.5359 - val_mean_absolute_percentage_error: 41.3049\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.22589\n",
      "Epoch 5/30\n",
      "488/488 [==============================] - 56s 114ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - mean_absolute_error: 0.1616 - mean_absolute_percentage_error: 105.4858 - val_loss: 0.3414 - val_mean_squared_error: 0.3414 - val_mean_absolute_error: 0.5567 - val_mean_absolute_percentage_error: 42.7880\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.22589\n",
      "Epoch 6/30\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - mean_absolute_error: 0.1607 - mean_absolute_percentage_error: 105.5660 - val_loss: 0.4292 - val_mean_squared_error: 0.4292 - val_mean_absolute_error: 0.6282 - val_mean_absolute_percentage_error: 48.3081\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.22589\n",
      "Epoch 7/30\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0492 - mean_squared_error: 0.0492 - mean_absolute_error: 0.1587 - mean_absolute_percentage_error: 104.9889 - val_loss: 0.3656 - val_mean_squared_error: 0.3656 - val_mean_absolute_error: 0.5749 - val_mean_absolute_percentage_error: 44.2199\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.22589\n",
      "Epoch 8/30\n",
      "488/488 [==============================] - 56s 116ms/step - loss: 0.0478 - mean_squared_error: 0.0478 - mean_absolute_error: 0.1569 - mean_absolute_percentage_error: 103.7676 - val_loss: 0.4092 - val_mean_squared_error: 0.4092 - val_mean_absolute_error: 0.6022 - val_mean_absolute_percentage_error: 46.5094\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.22589\n",
      "Epoch 9/30\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0465 - mean_squared_error: 0.0465 - mean_absolute_error: 0.1555 - mean_absolute_percentage_error: 102.8123 - val_loss: 0.5586 - val_mean_squared_error: 0.5586 - val_mean_absolute_error: 0.7005 - val_mean_absolute_percentage_error: 54.2800\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.22589\n",
      "Epoch 10/30\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0468 - mean_squared_error: 0.0468 - mean_absolute_error: 0.1562 - mean_absolute_percentage_error: 101.8598 - val_loss: 0.5957 - val_mean_squared_error: 0.5957 - val_mean_absolute_error: 0.7275 - val_mean_absolute_percentage_error: 55.9180\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.22589\n",
      "Epoch 11/30\n",
      "488/488 [==============================] - 57s 117ms/step - loss: 0.0454 - mean_squared_error: 0.0454 - mean_absolute_error: 0.1539 - mean_absolute_percentage_error: 98.8245 - val_loss: 0.7088 - val_mean_squared_error: 0.7088 - val_mean_absolute_error: 0.7944 - val_mean_absolute_percentage_error: 61.1303\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.22589\n",
      "Epoch 12/30\n",
      "488/488 [==============================] - 56s 115ms/step - loss: 0.0451 - mean_squared_error: 0.0451 - mean_absolute_error: 0.1533 - mean_absolute_percentage_error: 102.3057 - val_loss: 0.8349 - val_mean_squared_error: 0.8349 - val_mean_absolute_error: 0.8604 - val_mean_absolute_percentage_error: 66.5386\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.22589\n",
      "Epoch 00012: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.9\n",
      "Batches: 256\n",
      "Number of Neurons: 9\n",
      "Layers: 6\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_6_layers_tS_0.9_bs_256_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_6_layers_tS_0.9_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,142\n",
      "Trainable params: 3,142\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "244/244 [==============================] - 42s 134ms/step - loss: 0.1862 - mean_squared_error: 0.1862 - mean_absolute_error: 0.2823 - mean_absolute_percentage_error: 165.9877 - val_loss: 0.1532 - val_mean_squared_error: 0.1532 - val_mean_absolute_error: 0.3375 - val_mean_absolute_percentage_error: 25.1759\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.15316, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_256.h5\n",
      "Epoch 2/30\n",
      "244/244 [==============================] - 29s 118ms/step - loss: 0.0708 - mean_squared_error: 0.0708 - mean_absolute_error: 0.1819 - mean_absolute_percentage_error: 123.6115 - val_loss: 0.1843 - val_mean_squared_error: 0.1843 - val_mean_absolute_error: 0.3927 - val_mean_absolute_percentage_error: 29.7584\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.15316\n",
      "Epoch 3/30\n",
      "244/244 [==============================] - 28s 116ms/step - loss: 0.0640 - mean_squared_error: 0.0640 - mean_absolute_error: 0.1735 - mean_absolute_percentage_error: 117.3655 - val_loss: 0.1590 - val_mean_squared_error: 0.1590 - val_mean_absolute_error: 0.3596 - val_mean_absolute_percentage_error: 27.4594\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.15316\n",
      "Epoch 4/30\n",
      "244/244 [==============================] - 28s 115ms/step - loss: 0.0603 - mean_squared_error: 0.0603 - mean_absolute_error: 0.1695 - mean_absolute_percentage_error: 114.5333 - val_loss: 0.1867 - val_mean_squared_error: 0.1867 - val_mean_absolute_error: 0.4013 - val_mean_absolute_percentage_error: 30.6642\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.15316\n",
      "Epoch 5/30\n",
      "244/244 [==============================] - 29s 118ms/step - loss: 0.0574 - mean_squared_error: 0.0574 - mean_absolute_error: 0.1664 - mean_absolute_percentage_error: 113.9348 - val_loss: 0.1711 - val_mean_squared_error: 0.1711 - val_mean_absolute_error: 0.3839 - val_mean_absolute_percentage_error: 29.2963\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.15316\n",
      "Epoch 6/30\n",
      "244/244 [==============================] - 29s 117ms/step - loss: 0.0552 - mean_squared_error: 0.0552 - mean_absolute_error: 0.1642 - mean_absolute_percentage_error: 112.2623 - val_loss: 0.1392 - val_mean_squared_error: 0.1392 - val_mean_absolute_error: 0.3390 - val_mean_absolute_percentage_error: 25.9653\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.15316 to 0.13916, saving model to logs/model\\LSTM_6_layers_tS_0.9_bs_256.h5\n",
      "Epoch 7/30\n",
      "244/244 [==============================] - 28s 115ms/step - loss: 0.0536 - mean_squared_error: 0.0536 - mean_absolute_error: 0.1622 - mean_absolute_percentage_error: 109.5211 - val_loss: 0.1631 - val_mean_squared_error: 0.1631 - val_mean_absolute_error: 0.3762 - val_mean_absolute_percentage_error: 28.7548\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.13916\n",
      "Epoch 8/30\n",
      "244/244 [==============================] - 28s 115ms/step - loss: 0.0525 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1611 - mean_absolute_percentage_error: 109.8931 - val_loss: 0.1677 - val_mean_squared_error: 0.1677 - val_mean_absolute_error: 0.3821 - val_mean_absolute_percentage_error: 29.2597\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.13916\n",
      "Epoch 9/30\n",
      "244/244 [==============================] - 28s 117ms/step - loss: 0.0515 - mean_squared_error: 0.0515 - mean_absolute_error: 0.1599 - mean_absolute_percentage_error: 106.4790 - val_loss: 0.1592 - val_mean_squared_error: 0.1592 - val_mean_absolute_error: 0.3696 - val_mean_absolute_percentage_error: 28.3887\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.13916\n",
      "Epoch 10/30\n",
      "244/244 [==============================] - 29s 117ms/step - loss: 0.0506 - mean_squared_error: 0.0506 - mean_absolute_error: 0.1589 - mean_absolute_percentage_error: 106.0093 - val_loss: 0.1565 - val_mean_squared_error: 0.1565 - val_mean_absolute_error: 0.3673 - val_mean_absolute_percentage_error: 28.1929\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.13916\n",
      "Epoch 11/30\n",
      "244/244 [==============================] - 28s 115ms/step - loss: 0.0505 - mean_squared_error: 0.0505 - mean_absolute_error: 0.1588 - mean_absolute_percentage_error: 105.4572 - val_loss: 0.1956 - val_mean_squared_error: 0.1956 - val_mean_absolute_error: 0.4175 - val_mean_absolute_percentage_error: 32.0621\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.13916\n",
      "Epoch 12/30\n",
      "244/244 [==============================] - 28s 116ms/step - loss: 0.0492 - mean_squared_error: 0.0492 - mean_absolute_error: 0.1575 - mean_absolute_percentage_error: 103.5208 - val_loss: 0.2007 - val_mean_squared_error: 0.2007 - val_mean_absolute_error: 0.4242 - val_mean_absolute_percentage_error: 32.5517\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.13916\n",
      "Epoch 13/30\n",
      "244/244 [==============================] - 29s 117ms/step - loss: 0.0487 - mean_squared_error: 0.0487 - mean_absolute_error: 0.1569 - mean_absolute_percentage_error: 101.7566 - val_loss: 0.2047 - val_mean_squared_error: 0.2047 - val_mean_absolute_error: 0.4248 - val_mean_absolute_percentage_error: 32.7556\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.13916\n",
      "Epoch 14/30\n",
      "244/244 [==============================] - 28s 115ms/step - loss: 0.0481 - mean_squared_error: 0.0481 - mean_absolute_error: 0.1563 - mean_absolute_percentage_error: 99.6141 - val_loss: 0.2634 - val_mean_squared_error: 0.2634 - val_mean_absolute_error: 0.4812 - val_mean_absolute_percentage_error: 37.2813\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.13916\n",
      "Epoch 15/30\n",
      "244/244 [==============================] - 29s 117ms/step - loss: 0.0480 - mean_squared_error: 0.0480 - mean_absolute_error: 0.1561 - mean_absolute_percentage_error: 98.4819 - val_loss: 0.2937 - val_mean_squared_error: 0.2937 - val_mean_absolute_error: 0.5008 - val_mean_absolute_percentage_error: 38.9533\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.13916\n",
      "Epoch 16/30\n",
      "244/244 [==============================] - 29s 117ms/step - loss: 0.0473 - mean_squared_error: 0.0473 - mean_absolute_error: 0.1552 - mean_absolute_percentage_error: 98.6451 - val_loss: 0.3282 - val_mean_squared_error: 0.3282 - val_mean_absolute_error: 0.5269 - val_mean_absolute_percentage_error: 41.1491\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.13916\n",
      "Epoch 00016: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 64\n",
      "Number of Neurons: 9\n",
      "Layers: 7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_7_layers_tS_0.7_bs_64_I (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_64_0 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_64_1 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_64_2 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_64_3 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,826\n",
      "Trainable params: 3,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "757/757 [==============================] - 114s 134ms/step - loss: 0.1384 - mean_squared_error: 0.1384 - mean_absolute_error: 0.2444 - mean_absolute_percentage_error: 434.2502 - val_loss: 0.0349 - val_mean_squared_error: 0.0349 - val_mean_absolute_error: 0.1521 - val_mean_absolute_percentage_error: 64.2330\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03491, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_64.h5\n",
      "Epoch 2/30\n",
      "757/757 [==============================] - 61s 81ms/step - loss: 0.0716 - mean_squared_error: 0.0716 - mean_absolute_error: 0.1887 - mean_absolute_percentage_error: 352.8405 - val_loss: 0.0391 - val_mean_squared_error: 0.0391 - val_mean_absolute_error: 0.1678 - val_mean_absolute_percentage_error: 77.5805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00002: val_loss did not improve from 0.03491\n",
      "Epoch 3/30\n",
      "757/757 [==============================] - 63s 83ms/step - loss: 0.0653 - mean_squared_error: 0.0653 - mean_absolute_error: 0.1820 - mean_absolute_percentage_error: 366.6333 - val_loss: 0.0187 - val_mean_squared_error: 0.0187 - val_mean_absolute_error: 0.1061 - val_mean_absolute_percentage_error: 51.6045\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.03491 to 0.01866, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_64.h5\n",
      "Epoch 4/30\n",
      "757/757 [==============================] - 59s 77ms/step - loss: 0.0614 - mean_squared_error: 0.0614 - mean_absolute_error: 0.1778 - mean_absolute_percentage_error: 368.3101 - val_loss: 0.0273 - val_mean_squared_error: 0.0273 - val_mean_absolute_error: 0.1372 - val_mean_absolute_percentage_error: 66.3204\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.01866\n",
      "Epoch 5/30\n",
      "757/757 [==============================] - 60s 80ms/step - loss: 0.0586 - mean_squared_error: 0.0586 - mean_absolute_error: 0.1746 - mean_absolute_percentage_error: 328.4182 - val_loss: 0.0307 - val_mean_squared_error: 0.0307 - val_mean_absolute_error: 0.1492 - val_mean_absolute_percentage_error: 69.2707\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.01866\n",
      "Epoch 6/30\n",
      "757/757 [==============================] - 59s 77ms/step - loss: 0.0574 - mean_squared_error: 0.0574 - mean_absolute_error: 0.1732 - mean_absolute_percentage_error: 325.7482 - val_loss: 0.0179 - val_mean_squared_error: 0.0179 - val_mean_absolute_error: 0.1057 - val_mean_absolute_percentage_error: 44.7583\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.01866 to 0.01786, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_64.h5\n",
      "Epoch 7/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0554 - mean_squared_error: 0.0554 - mean_absolute_error: 0.1706 - mean_absolute_percentage_error: 327.6555 - val_loss: 0.0306 - val_mean_squared_error: 0.0306 - val_mean_absolute_error: 0.1484 - val_mean_absolute_percentage_error: 65.6660\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01786\n",
      "Epoch 8/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0544 - mean_squared_error: 0.0544 - mean_absolute_error: 0.1694 - mean_absolute_percentage_error: 312.1032 - val_loss: 0.0137 - val_mean_squared_error: 0.0137 - val_mean_absolute_error: 0.0914 - val_mean_absolute_percentage_error: 41.0995\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.01786 to 0.01375, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_64.h5\n",
      "Epoch 9/30\n",
      "757/757 [==============================] - 60s 80ms/step - loss: 0.0537 - mean_squared_error: 0.0537 - mean_absolute_error: 0.1689 - mean_absolute_percentage_error: 308.8877 - val_loss: 0.0223 - val_mean_squared_error: 0.0223 - val_mean_absolute_error: 0.1234 - val_mean_absolute_percentage_error: 50.2033\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01375\n",
      "Epoch 10/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0527 - mean_squared_error: 0.0527 - mean_absolute_error: 0.1673 - mean_absolute_percentage_error: 302.6778 - val_loss: 0.0199 - val_mean_squared_error: 0.0199 - val_mean_absolute_error: 0.1148 - val_mean_absolute_percentage_error: 45.6149\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01375\n",
      "Epoch 11/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0517 - mean_squared_error: 0.0517 - mean_absolute_error: 0.1661 - mean_absolute_percentage_error: 293.1410 - val_loss: 0.0214 - val_mean_squared_error: 0.0214 - val_mean_absolute_error: 0.1208 - val_mean_absolute_percentage_error: 44.0755\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01375\n",
      "Epoch 12/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - mean_absolute_error: 0.1649 - mean_absolute_percentage_error: 288.8807 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.1121 - val_mean_absolute_percentage_error: 42.1278\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01375\n",
      "Epoch 13/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0511 - mean_squared_error: 0.0511 - mean_absolute_error: 0.1649 - mean_absolute_percentage_error: 299.1391 - val_loss: 0.0175 - val_mean_squared_error: 0.0175 - val_mean_absolute_error: 0.1070 - val_mean_absolute_percentage_error: 36.7058\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01375\n",
      "Epoch 14/30\n",
      "757/757 [==============================] - 60s 79ms/step - loss: 0.0506 - mean_squared_error: 0.0506 - mean_absolute_error: 0.1643 - mean_absolute_percentage_error: 293.3957 - val_loss: 0.0158 - val_mean_squared_error: 0.0158 - val_mean_absolute_error: 0.1003 - val_mean_absolute_percentage_error: 35.4135\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01375\n",
      "Epoch 15/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0504 - mean_squared_error: 0.0504 - mean_absolute_error: 0.1638 - mean_absolute_percentage_error: 291.1563 - val_loss: 0.0248 - val_mean_squared_error: 0.0248 - val_mean_absolute_error: 0.1330 - val_mean_absolute_percentage_error: 44.5539\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01375\n",
      "Epoch 16/30\n",
      "757/757 [==============================] - 61s 81ms/step - loss: 0.0509 - mean_squared_error: 0.0509 - mean_absolute_error: 0.1645 - mean_absolute_percentage_error: 291.4348 - val_loss: 0.0282 - val_mean_squared_error: 0.0282 - val_mean_absolute_error: 0.1421 - val_mean_absolute_percentage_error: 45.1216\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01375\n",
      "Epoch 17/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0507 - mean_squared_error: 0.0507 - mean_absolute_error: 0.1645 - mean_absolute_percentage_error: 278.5442 - val_loss: 0.0250 - val_mean_squared_error: 0.0250 - val_mean_absolute_error: 0.1327 - val_mean_absolute_percentage_error: 43.4775\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01375\n",
      "Epoch 18/30\n",
      "757/757 [==============================] - 59s 78ms/step - loss: 0.0503 - mean_squared_error: 0.0503 - mean_absolute_error: 0.1636 - mean_absolute_percentage_error: 278.2894 - val_loss: 0.0295 - val_mean_squared_error: 0.0295 - val_mean_absolute_error: 0.1452 - val_mean_absolute_percentage_error: 47.2550\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01375\n",
      "Epoch 00018: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 128\n",
      "Number of Neurons: 9\n",
      "Layers: 7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_7_layers_tS_0.7_bs_128_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,826\n",
      "Trainable params: 3,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "379/379 [==============================] - 37s 84ms/step - loss: 0.1773 - mean_squared_error: 0.1773 - mean_absolute_error: 0.2767 - mean_absolute_percentage_error: 475.1175 - val_loss: 0.0237 - val_mean_squared_error: 0.0237 - val_mean_absolute_error: 0.1141 - val_mean_absolute_percentage_error: 64.0583\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02370, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_128.h5\n",
      "Epoch 2/30\n",
      "379/379 [==============================] - 29s 78ms/step - loss: 0.0781 - mean_squared_error: 0.0781 - mean_absolute_error: 0.1952 - mean_absolute_percentage_error: 380.3756 - val_loss: 0.0414 - val_mean_squared_error: 0.0414 - val_mean_absolute_error: 0.1577 - val_mean_absolute_percentage_error: 95.6047\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02370\n",
      "Epoch 3/30\n",
      "379/379 [==============================] - 30s 80ms/step - loss: 0.0704 - mean_squared_error: 0.0704 - mean_absolute_error: 0.1863 - mean_absolute_percentage_error: 371.5399 - val_loss: 0.0423 - val_mean_squared_error: 0.0423 - val_mean_absolute_error: 0.1640 - val_mean_absolute_percentage_error: 96.5756\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02370\n",
      "Epoch 4/30\n",
      "379/379 [==============================] - 31s 82ms/step - loss: 0.0662 - mean_squared_error: 0.0662 - mean_absolute_error: 0.1823 - mean_absolute_percentage_error: 348.6620 - val_loss: 0.0532 - val_mean_squared_error: 0.0532 - val_mean_absolute_error: 0.1911 - val_mean_absolute_percentage_error: 104.6140\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02370\n",
      "Epoch 5/30\n",
      "379/379 [==============================] - 31s 81ms/step - loss: 0.0626 - mean_squared_error: 0.0626 - mean_absolute_error: 0.1786 - mean_absolute_percentage_error: 332.3039 - val_loss: 0.0647 - val_mean_squared_error: 0.0647 - val_mean_absolute_error: 0.2187 - val_mean_absolute_percentage_error: 114.8030\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02370\n",
      "Epoch 6/30\n",
      "379/379 [==============================] - 31s 81ms/step - loss: 0.0605 - mean_squared_error: 0.0605 - mean_absolute_error: 0.1764 - mean_absolute_percentage_error: 317.8282 - val_loss: 0.0632 - val_mean_squared_error: 0.0632 - val_mean_absolute_error: 0.2178 - val_mean_absolute_percentage_error: 93.4142\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02370\n",
      "Epoch 7/30\n",
      "379/379 [==============================] - 31s 83ms/step - loss: 0.0590 - mean_squared_error: 0.0590 - mean_absolute_error: 0.1748 - mean_absolute_percentage_error: 308.0351 - val_loss: 0.0609 - val_mean_squared_error: 0.0609 - val_mean_absolute_error: 0.2126 - val_mean_absolute_percentage_error: 88.6373\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02370\n",
      "Epoch 8/30\n",
      "379/379 [==============================] - 30s 78ms/step - loss: 0.0573 - mean_squared_error: 0.0573 - mean_absolute_error: 0.1725 - mean_absolute_percentage_error: 308.9260 - val_loss: 0.0876 - val_mean_squared_error: 0.0876 - val_mean_absolute_error: 0.2533 - val_mean_absolute_percentage_error: 111.8628\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02370\n",
      "Epoch 9/30\n",
      "379/379 [==============================] - 30s 80ms/step - loss: 0.0564 - mean_squared_error: 0.0564 - mean_absolute_error: 0.1716 - mean_absolute_percentage_error: 302.9884 - val_loss: 0.0827 - val_mean_squared_error: 0.0827 - val_mean_absolute_error: 0.2462 - val_mean_absolute_percentage_error: 95.7679\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02370\n",
      "Epoch 10/30\n",
      "379/379 [==============================] - 31s 81ms/step - loss: 0.0555 - mean_squared_error: 0.0555 - mean_absolute_error: 0.1706 - mean_absolute_percentage_error: 314.0073 - val_loss: 0.0792 - val_mean_squared_error: 0.0792 - val_mean_absolute_error: 0.2394 - val_mean_absolute_percentage_error: 99.8145\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02370\n",
      "Epoch 11/30\n",
      "379/379 [==============================] - 30s 78ms/step - loss: 0.0548 - mean_squared_error: 0.0548 - mean_absolute_error: 0.1696 - mean_absolute_percentage_error: 306.1442 - val_loss: 0.0756 - val_mean_squared_error: 0.0756 - val_mean_absolute_error: 0.2319 - val_mean_absolute_percentage_error: 98.3145\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02370\n",
      "Epoch 00011: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 256\n",
      "Number of Neurons: 9\n",
      "Layers: 7\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_7_layers_tS_0.7_bs_256_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_7_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 3,826\n",
      "Trainable params: 3,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "190/190 [==============================] - 22s 93ms/step - loss: 0.2821 - mean_squared_error: 0.2821 - mean_absolute_error: 0.3530 - mean_absolute_percentage_error: 555.9699 - val_loss: 0.0388 - val_mean_squared_error: 0.0388 - val_mean_absolute_error: 0.1508 - val_mean_absolute_percentage_error: 82.0116\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03880, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_256.h5\n",
      "Epoch 2/30\n",
      "190/190 [==============================] - 16s 85ms/step - loss: 0.0942 - mean_squared_error: 0.0942 - mean_absolute_error: 0.2101 - mean_absolute_percentage_error: 358.7003 - val_loss: 0.0243 - val_mean_squared_error: 0.0243 - val_mean_absolute_error: 0.1138 - val_mean_absolute_percentage_error: 66.4104\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03880 to 0.02428, saving model to logs/model\\LSTM_7_layers_tS_0.7_bs_256.h5\n",
      "Epoch 3/30\n",
      "190/190 [==============================] - 16s 84ms/step - loss: 0.0825 - mean_squared_error: 0.0825 - mean_absolute_error: 0.1980 - mean_absolute_percentage_error: 354.9630 - val_loss: 0.0268 - val_mean_squared_error: 0.0268 - val_mean_absolute_error: 0.1204 - val_mean_absolute_percentage_error: 77.1193\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02428\n",
      "Epoch 4/30\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.0765 - mean_squared_error: 0.0765 - mean_absolute_error: 0.1917 - mean_absolute_percentage_error: 364.9196 - val_loss: 0.0272 - val_mean_squared_error: 0.0272 - val_mean_absolute_error: 0.1222 - val_mean_absolute_percentage_error: 75.4083\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02428\n",
      "Epoch 5/30\n",
      "190/190 [==============================] - 17s 87ms/step - loss: 0.0723 - mean_squared_error: 0.0723 - mean_absolute_error: 0.1872 - mean_absolute_percentage_error: 350.1844 - val_loss: 0.0297 - val_mean_squared_error: 0.0297 - val_mean_absolute_error: 0.1287 - val_mean_absolute_percentage_error: 88.3954\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02428\n",
      "Epoch 6/30\n",
      "190/190 [==============================] - 17s 89ms/step - loss: 0.0694 - mean_squared_error: 0.0694 - mean_absolute_error: 0.1840 - mean_absolute_percentage_error: 355.8784 - val_loss: 0.0361 - val_mean_squared_error: 0.0361 - val_mean_absolute_error: 0.1433 - val_mean_absolute_percentage_error: 95.7571\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02428\n",
      "Epoch 7/30\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.0674 - mean_squared_error: 0.0674 - mean_absolute_error: 0.1821 - mean_absolute_percentage_error: 340.1934 - val_loss: 0.0375 - val_mean_squared_error: 0.0375 - val_mean_absolute_error: 0.1416 - val_mean_absolute_percentage_error: 98.1521\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02428\n",
      "Epoch 8/30\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.0655 - mean_squared_error: 0.0655 - mean_absolute_error: 0.1801 - mean_absolute_percentage_error: 342.5900 - val_loss: 0.0397 - val_mean_squared_error: 0.0397 - val_mean_absolute_error: 0.1456 - val_mean_absolute_percentage_error: 104.1368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02428\n",
      "Epoch 9/30\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.0637 - mean_squared_error: 0.0637 - mean_absolute_error: 0.1783 - mean_absolute_percentage_error: 327.9629 - val_loss: 0.0535 - val_mean_squared_error: 0.0535 - val_mean_absolute_error: 0.1658 - val_mean_absolute_percentage_error: 116.2015\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02428\n",
      "Epoch 10/30\n",
      "190/190 [==============================] - 16s 86ms/step - loss: 0.0617 - mean_squared_error: 0.0617 - mean_absolute_error: 0.1762 - mean_absolute_percentage_error: 326.5558 - val_loss: 0.0659 - val_mean_squared_error: 0.0659 - val_mean_absolute_error: 0.2074 - val_mean_absolute_percentage_error: 121.6943\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02428\n",
      "Epoch 11/30\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.0607 - mean_squared_error: 0.0607 - mean_absolute_error: 0.1754 - mean_absolute_percentage_error: 318.3307 - val_loss: 0.0749 - val_mean_squared_error: 0.0749 - val_mean_absolute_error: 0.2167 - val_mean_absolute_percentage_error: 121.9315\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02428\n",
      "Epoch 12/30\n",
      "190/190 [==============================] - 17s 88ms/step - loss: 0.0624 - mean_squared_error: 0.0624 - mean_absolute_error: 0.1793 - mean_absolute_percentage_error: 318.5799 - val_loss: 0.0429 - val_mean_squared_error: 0.0429 - val_mean_absolute_error: 0.1646 - val_mean_absolute_percentage_error: 97.4865\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.02428\n",
      "Epoch 00012: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 64\n",
      "Number of Neurons: 9\n",
      "Layers: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_8_layers_tS_0.7_bs_64_I (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_64_0 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_64_1 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_64_2 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_64_3 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_64_4 (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 4,510\n",
      "Trainable params: 4,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "757/757 [==============================] - 82s 100ms/step - loss: 0.1349 - mean_squared_error: 0.1349 - mean_absolute_error: 0.2425 - mean_absolute_percentage_error: 394.3606 - val_loss: 0.0195 - val_mean_squared_error: 0.0195 - val_mean_absolute_error: 0.0952 - val_mean_absolute_percentage_error: 47.5802\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.01951, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_64.h5\n",
      "Epoch 2/30\n",
      "757/757 [==============================] - 73s 96ms/step - loss: 0.0734 - mean_squared_error: 0.0734 - mean_absolute_error: 0.1892 - mean_absolute_percentage_error: 345.7314 - val_loss: 0.0177 - val_mean_squared_error: 0.0177 - val_mean_absolute_error: 0.0944 - val_mean_absolute_percentage_error: 58.7824\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.01951 to 0.01771, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_64.h5\n",
      "Epoch 3/30\n",
      "757/757 [==============================] - 73s 96ms/step - loss: 0.0665 - mean_squared_error: 0.0665 - mean_absolute_error: 0.1818 - mean_absolute_percentage_error: 340.4739 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.1033 - val_mean_absolute_percentage_error: 56.4346\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.01771\n",
      "Epoch 4/30\n",
      "757/757 [==============================] - 75s 99ms/step - loss: 0.0628 - mean_squared_error: 0.0628 - mean_absolute_error: 0.1778 - mean_absolute_percentage_error: 305.8346 - val_loss: 0.0145 - val_mean_squared_error: 0.0145 - val_mean_absolute_error: 0.0890 - val_mean_absolute_percentage_error: 48.6346\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.01771 to 0.01452, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_64.h5\n",
      "Epoch 5/30\n",
      "757/757 [==============================] - 77s 102ms/step - loss: 0.0598 - mean_squared_error: 0.0598 - mean_absolute_error: 0.1743 - mean_absolute_percentage_error: 298.1655 - val_loss: 0.0154 - val_mean_squared_error: 0.0154 - val_mean_absolute_error: 0.0911 - val_mean_absolute_percentage_error: 40.1629\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.01452\n",
      "Epoch 6/30\n",
      "757/757 [==============================] - 74s 97ms/step - loss: 0.0606 - mean_squared_error: 0.0606 - mean_absolute_error: 0.1769 - mean_absolute_percentage_error: 292.8931 - val_loss: 0.0170 - val_mean_squared_error: 0.0170 - val_mean_absolute_error: 0.1000 - val_mean_absolute_percentage_error: 53.7660\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.01452\n",
      "Epoch 7/30\n",
      "757/757 [==============================] - 77s 102ms/step - loss: 0.0572 - mean_squared_error: 0.0572 - mean_absolute_error: 0.1721 - mean_absolute_percentage_error: 292.3073 - val_loss: 0.0269 - val_mean_squared_error: 0.0269 - val_mean_absolute_error: 0.1309 - val_mean_absolute_percentage_error: 70.3682\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01452\n",
      "Epoch 8/30\n",
      "757/757 [==============================] - 76s 101ms/step - loss: 0.0555 - mean_squared_error: 0.0555 - mean_absolute_error: 0.1703 - mean_absolute_percentage_error: 285.2387 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.1104 - val_mean_absolute_percentage_error: 50.6448\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01452\n",
      "Epoch 9/30\n",
      "757/757 [==============================] - 75s 99ms/step - loss: 0.0543 - mean_squared_error: 0.0543 - mean_absolute_error: 0.1694 - mean_absolute_percentage_error: 297.6160 - val_loss: 0.0211 - val_mean_squared_error: 0.0211 - val_mean_absolute_error: 0.1175 - val_mean_absolute_percentage_error: 49.4797ed_error: 0.0544 - mean_absolute_er\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01452\n",
      "Epoch 10/30\n",
      "757/757 [==============================] - 77s 102ms/step - loss: 0.0533 - mean_squared_error: 0.0533 - mean_absolute_error: 0.1674 - mean_absolute_percentage_error: 268.1693 - val_loss: 0.0344 - val_mean_squared_error: 0.0344 - val_mean_absolute_error: 0.1496 - val_mean_absolute_percentage_error: 67.6785\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01452\n",
      "Epoch 11/30\n",
      "757/757 [==============================] - 78s 103ms/step - loss: 0.0529 - mean_squared_error: 0.0529 - mean_absolute_error: 0.1670 - mean_absolute_percentage_error: 273.8553 - val_loss: 0.0143 - val_mean_squared_error: 0.0143 - val_mean_absolute_error: 0.0916 - val_mean_absolute_percentage_error: 44.7270\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.01452 to 0.01434, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_64.h5\n",
      "Epoch 12/30\n",
      "757/757 [==============================] - 75s 99ms/step - loss: 0.0529 - mean_squared_error: 0.0529 - mean_absolute_error: 0.1666 - mean_absolute_percentage_error: 268.1049 - val_loss: 0.0231 - val_mean_squared_error: 0.0231 - val_mean_absolute_error: 0.1220 - val_mean_absolute_percentage_error: 48.4286\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01434\n",
      "Epoch 13/30\n",
      "757/757 [==============================] - 74s 98ms/step - loss: 0.0514 - mean_squared_error: 0.0514 - mean_absolute_error: 0.1645 - mean_absolute_percentage_error: 272.5130 - val_loss: 0.0205 - val_mean_squared_error: 0.0205 - val_mean_absolute_error: 0.1133 - val_mean_absolute_percentage_error: 45.0440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01434\n",
      "Epoch 14/30\n",
      "757/757 [==============================] - 77s 101ms/step - loss: 0.0525 - mean_squared_error: 0.0525 - mean_absolute_error: 0.1656 - mean_absolute_percentage_error: 260.8055 - val_loss: 0.0278 - val_mean_squared_error: 0.0278 - val_mean_absolute_error: 0.1324 - val_mean_absolute_percentage_error: 56.5429\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01434\n",
      "Epoch 15/30\n",
      "757/757 [==============================] - 77s 102ms/step - loss: 0.0515 - mean_squared_error: 0.0515 - mean_absolute_error: 0.1647 - mean_absolute_percentage_error: 267.8443 - val_loss: 0.0249 - val_mean_squared_error: 0.0249 - val_mean_absolute_error: 0.1285 - val_mean_absolute_percentage_error: 52.4437\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01434\n",
      "Epoch 16/30\n",
      "757/757 [==============================] - 77s 102ms/step - loss: 0.0506 - mean_squared_error: 0.0506 - mean_absolute_error: 0.1633 - mean_absolute_percentage_error: 258.8280 - val_loss: 0.0352 - val_mean_squared_error: 0.0352 - val_mean_absolute_error: 0.1471 - val_mean_absolute_percentage_error: 52.5950\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01434\n",
      "Epoch 17/30\n",
      "757/757 [==============================] - 74s 98ms/step - loss: 0.0499 - mean_squared_error: 0.0499 - mean_absolute_error: 0.1618 - mean_absolute_percentage_error: 280.5328 - val_loss: 0.0318 - val_mean_squared_error: 0.0318 - val_mean_absolute_error: 0.1422 - val_mean_absolute_percentage_error: 49.6481\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01434\n",
      "Epoch 18/30\n",
      "757/757 [==============================] - 76s 100ms/step - loss: 0.0494 - mean_squared_error: 0.0494 - mean_absolute_error: 0.1609 - mean_absolute_percentage_error: 259.3169 - val_loss: 0.0341 - val_mean_squared_error: 0.0341 - val_mean_absolute_error: 0.1499 - val_mean_absolute_percentage_error: 55.5900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.01434\n",
      "Epoch 19/30\n",
      "757/757 [==============================] - 74s 97ms/step - loss: 0.0496 - mean_squared_error: 0.0496 - mean_absolute_error: 0.1614 - mean_absolute_percentage_error: 289.3672 - val_loss: 0.0406 - val_mean_squared_error: 0.0406 - val_mean_absolute_error: 0.1594 - val_mean_absolute_percentage_error: 56.5966\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01434\n",
      "Epoch 20/30\n",
      "757/757 [==============================] - 77s 102ms/step - loss: 0.0498 - mean_squared_error: 0.0498 - mean_absolute_error: 0.1620 - mean_absolute_percentage_error: 265.7615 - val_loss: 0.0564 - val_mean_squared_error: 0.0564 - val_mean_absolute_error: 0.2022 - val_mean_absolute_percentage_error: 67.5463\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01434\n",
      "Epoch 21/30\n",
      "757/757 [==============================] - 76s 100ms/step - loss: 0.0492 - mean_squared_error: 0.0492 - mean_absolute_error: 0.1606 - mean_absolute_percentage_error: 249.4185 - val_loss: 0.0375 - val_mean_squared_error: 0.0375 - val_mean_absolute_error: 0.1588 - val_mean_absolute_percentage_error: 51.3101\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.01434\n",
      "Epoch 00021: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 128\n",
      "Number of Neurons: 9\n",
      "Layers: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_8_layers_tS_0.7_bs_128_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_128_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 4,510\n",
      "Trainable params: 4,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "379/379 [==============================] - 47s 110ms/step - loss: 0.1727 - mean_squared_error: 0.1727 - mean_absolute_error: 0.2715 - mean_absolute_percentage_error: 390.2355 - val_loss: 0.0211 - val_mean_squared_error: 0.0211 - val_mean_absolute_error: 0.1055 - val_mean_absolute_percentage_error: 51.1027\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02105, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_128.h5\n",
      "Epoch 2/30\n",
      "379/379 [==============================] - 40s 104ms/step - loss: 0.0784 - mean_squared_error: 0.0784 - mean_absolute_error: 0.1935 - mean_absolute_percentage_error: 367.6905 - val_loss: 0.0220 - val_mean_squared_error: 0.0220 - val_mean_absolute_error: 0.1124 - val_mean_absolute_percentage_error: 64.0630\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02105\n",
      "Epoch 3/30\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.0704 - mean_squared_error: 0.0704 - mean_absolute_error: 0.1853 - mean_absolute_percentage_error: 344.0124 - val_loss: 0.0254 - val_mean_squared_error: 0.0254 - val_mean_absolute_error: 0.1273 - val_mean_absolute_percentage_error: 73.4104\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02105\n",
      "Epoch 4/30\n",
      "379/379 [==============================] - 39s 104ms/step - loss: 0.0660 - mean_squared_error: 0.0660 - mean_absolute_error: 0.1817 - mean_absolute_percentage_error: 327.0280 - val_loss: 0.0234 - val_mean_squared_error: 0.0234 - val_mean_absolute_error: 0.1195 - val_mean_absolute_percentage_error: 57.3706\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02105\n",
      "Epoch 5/30\n",
      "379/379 [==============================] - 41s 108ms/step - loss: 0.0626 - mean_squared_error: 0.0626 - mean_absolute_error: 0.1781 - mean_absolute_percentage_error: 327.7012 - val_loss: 0.0208 - val_mean_squared_error: 0.0208 - val_mean_absolute_error: 0.1139 - val_mean_absolute_percentage_error: 62.8093\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.02105 to 0.02084, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_128.h5\n",
      "Epoch 6/30\n",
      "379/379 [==============================] - 41s 109ms/step - loss: 0.0618 - mean_squared_error: 0.0618 - mean_absolute_error: 0.1776 - mean_absolute_percentage_error: 325.0447 - val_loss: 0.0188 - val_mean_squared_error: 0.0188 - val_mean_absolute_error: 0.1091 - val_mean_absolute_percentage_error: 66.0047\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.02084 to 0.01880, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_128.h5\n",
      "Epoch 7/30\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.0602 - mean_squared_error: 0.0602 - mean_absolute_error: 0.1754 - mean_absolute_percentage_error: 305.1525 - val_loss: 0.0213 - val_mean_squared_error: 0.0213 - val_mean_absolute_error: 0.1185 - val_mean_absolute_percentage_error: 71.5237\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.01880\n",
      "Epoch 8/30\n",
      "379/379 [==============================] - 39s 102ms/step - loss: 0.0582 - mean_squared_error: 0.0582 - mean_absolute_error: 0.1737 - mean_absolute_percentage_error: 299.8065 - val_loss: 0.0239 - val_mean_squared_error: 0.0239 - val_mean_absolute_error: 0.1267 - val_mean_absolute_percentage_error: 74.6846\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.01880\n",
      "Epoch 9/30\n",
      "379/379 [==============================] - 37s 97ms/step - loss: 0.0565 - mean_squared_error: 0.0565 - mean_absolute_error: 0.1720 - mean_absolute_percentage_error: 290.2499 - val_loss: 0.0311 - val_mean_squared_error: 0.0311 - val_mean_absolute_error: 0.1460 - val_mean_absolute_percentage_error: 78.8314\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.01880\n",
      "Epoch 10/30\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.0555 - mean_squared_error: 0.0555 - mean_absolute_error: 0.1710 - mean_absolute_percentage_error: 289.4015 - val_loss: 0.0298 - val_mean_squared_error: 0.0298 - val_mean_absolute_error: 0.1421 - val_mean_absolute_percentage_error: 87.8194\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.01880\n",
      "Epoch 11/30\n",
      "379/379 [==============================] - 42s 111ms/step - loss: 0.0549 - mean_squared_error: 0.0549 - mean_absolute_error: 0.1704 - mean_absolute_percentage_error: 298.9885 - val_loss: 0.0266 - val_mean_squared_error: 0.0266 - val_mean_absolute_error: 0.1351 - val_mean_absolute_percentage_error: 80.4820\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.01880\n",
      "Epoch 12/30\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.0534 - mean_squared_error: 0.0534 - mean_absolute_error: 0.1681 - mean_absolute_percentage_error: 301.8713 - val_loss: 0.0282 - val_mean_squared_error: 0.0282 - val_mean_absolute_error: 0.1388 - val_mean_absolute_percentage_error: 75.2409\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.01880\n",
      "Epoch 13/30\n",
      "379/379 [==============================] - 40s 106ms/step - loss: 0.0535 - mean_squared_error: 0.0535 - mean_absolute_error: 0.1684 - mean_absolute_percentage_error: 306.5768 - val_loss: 0.0232 - val_mean_squared_error: 0.0232 - val_mean_absolute_error: 0.1249 - val_mean_absolute_percentage_error: 72.5860\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.01880\n",
      "Epoch 14/30\n",
      "379/379 [==============================] - 42s 110ms/step - loss: 0.0520 - mean_squared_error: 0.0520 - mean_absolute_error: 0.1661 - mean_absolute_percentage_error: 297.6523 - val_loss: 0.0226 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.1239 - val_mean_absolute_percentage_error: 71.3655\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.01880\n",
      "Epoch 15/30\n",
      "379/379 [==============================] - 40s 105ms/step - loss: 0.0521 - mean_squared_error: 0.0521 - mean_absolute_error: 0.1663 - mean_absolute_percentage_error: 302.1267 - val_loss: 0.0310 - val_mean_squared_error: 0.0310 - val_mean_absolute_error: 0.1458 - val_mean_absolute_percentage_error: 90.4331\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01880\n",
      "Epoch 16/30\n",
      "379/379 [==============================] - 41s 109ms/step - loss: 0.0517 - mean_squared_error: 0.0517 - mean_absolute_error: 0.1658 - mean_absolute_percentage_error: 308.8002 - val_loss: 0.0226 - val_mean_squared_error: 0.0226 - val_mean_absolute_error: 0.1235 - val_mean_absolute_percentage_error: 78.3679\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01880\n",
      "Epoch 00016: early stopping\n",
      "Number of look back minutes: 360\n",
      "Number of features: 20\n",
      "TrainTest split: 0.7\n",
      "Batches: 256\n",
      "Number of Neurons: 9\n",
      "Layers: 8\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "LSTM_8_layers_tS_0.7_bs_256_ (None, 360, 9)            1080      \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "LSTM_8_layers_tS_0.7_bs_256_ (None, 360, 9)            684       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 360, 9)            0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 360, 1)            10        \n",
      "=================================================================\n",
      "Total params: 4,510\n",
      "Trainable params: 4,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "190/190 [==============================] - 29s 123ms/step - loss: 0.3227 - mean_squared_error: 0.3227 - mean_absolute_error: 0.3876 - mean_absolute_percentage_error: 476.3949 - val_loss: 0.0267 - val_mean_squared_error: 0.0267 - val_mean_absolute_error: 0.1199 - val_mean_absolute_percentage_error: 37.5428\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.02667, saving model to logs/model\\LSTM_8_layers_tS_0.7_bs_256.h5\n",
      "Epoch 2/30\n",
      "190/190 [==============================] - 21s 110ms/step - loss: 0.0968 - mean_squared_error: 0.0968 - mean_absolute_error: 0.2144 - mean_absolute_percentage_error: 383.3692 - val_loss: 0.0360 - val_mean_squared_error: 0.0360 - val_mean_absolute_error: 0.1545 - val_mean_absolute_percentage_error: 65.3866\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 0.02667\n",
      "Epoch 3/30\n",
      "190/190 [==============================] - 20s 107ms/step - loss: 0.0841 - mean_squared_error: 0.0841 - mean_absolute_error: 0.2017 - mean_absolute_percentage_error: 379.8437 - val_loss: 0.0331 - val_mean_squared_error: 0.0331 - val_mean_absolute_error: 0.1436 - val_mean_absolute_percentage_error: 74.0833\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.02667\n",
      "Epoch 4/30\n",
      "190/190 [==============================] - 21s 110ms/step - loss: 0.0765 - mean_squared_error: 0.0765 - mean_absolute_error: 0.1934 - mean_absolute_percentage_error: 351.6224 - val_loss: 0.0577 - val_mean_squared_error: 0.0577 - val_mean_absolute_error: 0.2013 - val_mean_absolute_percentage_error: 93.2636\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.02667\n",
      "Epoch 5/30\n",
      "190/190 [==============================] - 22s 115ms/step - loss: 0.0717 - mean_squared_error: 0.0717 - mean_absolute_error: 0.1880 - mean_absolute_percentage_error: 334.4807 - val_loss: 0.0402 - val_mean_squared_error: 0.0402 - val_mean_absolute_error: 0.1552 - val_mean_absolute_percentage_error: 93.2085\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.02667\n",
      "Epoch 6/30\n",
      "190/190 [==============================] - 23s 119ms/step - loss: 0.0685 - mean_squared_error: 0.0685 - mean_absolute_error: 0.1845 - mean_absolute_percentage_error: 324.9610 - val_loss: 0.0481 - val_mean_squared_error: 0.0481 - val_mean_absolute_error: 0.1742 - val_mean_absolute_percentage_error: 102.0828\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.02667\n",
      "Epoch 7/30\n",
      "190/190 [==============================] - 22s 116ms/step - loss: 0.0660 - mean_squared_error: 0.0660 - mean_absolute_error: 0.1818 - mean_absolute_percentage_error: 330.4362 - val_loss: 0.0510 - val_mean_squared_error: 0.0510 - val_mean_absolute_error: 0.1837 - val_mean_absolute_percentage_error: 101.8888\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.02667\n",
      "Epoch 8/30\n",
      "190/190 [==============================] - 22s 115ms/step - loss: 0.0643 - mean_squared_error: 0.0643 - mean_absolute_error: 0.1800 - mean_absolute_percentage_error: 314.8009 - val_loss: 0.0587 - val_mean_squared_error: 0.0587 - val_mean_absolute_error: 0.1958 - val_mean_absolute_percentage_error: 113.9342\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.02667\n",
      "Epoch 9/30\n",
      "190/190 [==============================] - 22s 116ms/step - loss: 0.0626 - mean_squared_error: 0.0626 - mean_absolute_error: 0.1782 - mean_absolute_percentage_error: 318.9300 - val_loss: 0.0577 - val_mean_squared_error: 0.0577 - val_mean_absolute_error: 0.1947 - val_mean_absolute_percentage_error: 113.0853\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.02667\n",
      "Epoch 10/30\n",
      "190/190 [==============================] - 21s 113ms/step - loss: 0.0613 - mean_squared_error: 0.0613 - mean_absolute_error: 0.1771 - mean_absolute_percentage_error: 305.4029 - val_loss: 0.0626 - val_mean_squared_error: 0.0626 - val_mean_absolute_error: 0.2031 - val_mean_absolute_percentage_error: 120.2801\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.02667\n",
      "Epoch 11/30\n",
      "190/190 [==============================] - 21s 108ms/step - loss: 0.0603 - mean_squared_error: 0.0603 - mean_absolute_error: 0.1759 - mean_absolute_percentage_error: 316.3916 - val_loss: 0.0677 - val_mean_squared_error: 0.0677 - val_mean_absolute_error: 0.2110 - val_mean_absolute_percentage_error: 125.2306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.02667\n",
      "Epoch 00011: early stopping\n",
      "Wall time: 2h 53min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop different models\n",
    "for LSTM_dict in LSTM_dict_list:\n",
    "    # Split the data based on split size\n",
    "    train, test = transform.GetTrainTest(df, LSTM_dict[\"train_split\"])\n",
    "    # Scale the data\n",
    "    scaled_train, scaled_test, scaler = transform.scaleData(train, test)\n",
    "    \n",
    "    # Transform our dataset into features and label variable and reshaped 3D \n",
    "    # First the Train Dataset\n",
    "    X_train, y_train = transform.reformatDataset(lookback_minutes, prediction_minutes, scaled_train)\n",
    "    # Second the Test Dataset\n",
    "    X_test, y_test = transform.reformatDataset(lookback_minutes, prediction_minutes, scaled_test)\n",
    "    \n",
    "    #modelName = 'LSTM_model_layers_' + str(LSTMLayers+2) + '_train_split_' + str(split)\n",
    "    modelName = 'LSTM_' + str(LSTM_dict[\"LSTMLayers\"]+3) + '_layers_tS_' + str(LSTM_dict[\"train_split\"]) + '_bs_'+str(LSTM_dict[\"custom_batch_size\"])\n",
    "    \n",
    "    # Create the model\n",
    "    model1 = Trainer(loss ='mse', optimizer='adam', epochs=LSTM_dict[\"custom_epochs\"], X_train=X_train, y_train=y_train, \n",
    "                 X_test=X_test, y_test=y_test, activation='tanh', layerNumber=LSTM_dict[\"LSTMLayers\"], modelName=modelName, \n",
    "                 patience=LSTM_dict[\"custom_patience\"], customBatchSize=LSTM_dict[\"custom_batch_size\"], \n",
    "                    neuron_scale_factor = LSTM_dict[\"neuronScaleFactor\"], split = LSTM_dict[\"train_split\"])\n",
    "    model, n_neurons = model1.createModel()\n",
    "    \n",
    "    history = model1.trainModel()\n",
    "    history.model.save('./logs/model/' + modelName + '.h5')\n",
    "\n",
    "    \n",
    "    # Model Evaluation\n",
    "    evaluation = pd.DataFrame(columns = ['Model', 'Test Size', 'MAE', 'MSE', 'Model Details'])\n",
    "    evaluation.loc[0] = ['LSTM', str(LSTM_dict[\"train_split\"]), min(history.history['mean_absolute_error']), \n",
    "                         min(history.history['mean_squared_error']), modelName]\n",
    "    # Write data to database\n",
    "    engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\".format(host=hostname, db=dbName, user=uname, pw=pwd))\n",
    "    evaluation.to_sql(name='model_evaluation', con=engine, if_exists='append', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3a0ad5c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-07T14:30:59.773809Z",
     "start_time": "2021-11-07T14:30:59.759768Z"
    }
   },
   "outputs": [],
   "source": [
    "#!kill 15864"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc3a194",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-11-10T18:28:24.643753Z",
     "start_time": "2021-11-10T18:28:19.482118Z"
    },
    "scrolled": false
   },
   "source": [
    "#https://stackoverflow.com/questions/57228487/valueerror-duplicate-plugins-for-name-projector\n",
    "#https://github.com/tensorflow/tensorboard/issues/2483\n",
    "#https://www.tensorflow.org/tensorboard/tensorboard_in_notebooks\n",
    "#https://www.programcreek.com/python/example/104420/keras.callbacks.TensorBoard\n",
    "\n",
    "%tensorboard --port 6006 --logdir logs/fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9d8f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
